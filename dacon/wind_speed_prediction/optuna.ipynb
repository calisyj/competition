{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3638f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:85: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:143: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "[I 2023-07-27 23:04:14,428] A new study created in memory with name: no-name-6f8148a5-945f-425a-a6f3-c19ed3a652f2\n",
      "[I 2023-07-27 23:06:27,748] Trial 0 finished with value: 0.49655931132679354 and parameters: {'n_estimators': 192, 'max_features': 0.7772181513627047, 'min_samples_split': 11, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.49655931132679354.\n",
      "[I 2023-07-27 23:06:47,497] Trial 1 finished with value: 0.6201389973996193 and parameters: {'n_estimators': 75, 'max_features': 0.2913444962591931, 'min_samples_split': 18, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.49655931132679354.\n",
      "[I 2023-07-27 23:08:33,119] Trial 2 finished with value: 0.4911106901010075 and parameters: {'n_estimators': 181, 'max_features': 0.615890156167702, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.4911106901010075.\n",
      "[I 2023-07-27 23:09:18,584] Trial 3 finished with value: 0.6180699759124821 and parameters: {'n_estimators': 148, 'max_features': 0.358840990022779, 'min_samples_split': 3, 'min_samples_leaf': 18}. Best is trial 2 with value: 0.4911106901010075.\n",
      "[I 2023-07-27 23:10:31,965] Trial 4 finished with value: 0.4283603156422992 and parameters: {'n_estimators': 100, 'max_features': 0.7003610992690507, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:11:03,042] Trial 5 finished with value: 0.6701475876473559 and parameters: {'n_estimators': 145, 'max_features': 0.24622490249336265, 'min_samples_split': 12, 'min_samples_leaf': 20}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:11:30,416] Trial 6 finished with value: 0.48707058493967786 and parameters: {'n_estimators': 95, 'max_features': 0.2170269800061666, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:11:59,514] Trial 7 finished with value: 0.5623752449738427 and parameters: {'n_estimators': 149, 'max_features': 0.16496173749638948, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:12:48,820] Trial 8 finished with value: 0.6285236905895941 and parameters: {'n_estimators': 185, 'max_features': 0.2819021107314914, 'min_samples_split': 7, 'min_samples_leaf': 17}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:13:53,399] Trial 9 finished with value: 0.5981780397825236 and parameters: {'n_estimators': 123, 'max_features': 0.610926841071601, 'min_samples_split': 11, 'min_samples_leaf': 19}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:14:50,864] Trial 10 finished with value: 0.4484020978822906 and parameters: {'n_estimators': 60, 'max_features': 0.9382390927113994, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:15:41,810] Trial 11 finished with value: 0.44755792208115786 and parameters: {'n_estimators': 51, 'max_features': 0.9753976281227661, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:17:22,421] Trial 12 finished with value: 0.42971194623153897 and parameters: {'n_estimators': 100, 'max_features': 0.9245157229235176, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:18:35,525] Trial 13 finished with value: 0.5390267562987123 and parameters: {'n_estimators': 105, 'max_features': 0.7837812472974183, 'min_samples_split': 15, 'min_samples_leaf': 13}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:19:50,518] Trial 14 finished with value: 0.444925014490899 and parameters: {'n_estimators': 88, 'max_features': 0.8167313562178105, 'min_samples_split': 15, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:20:54,642] Trial 15 finished with value: 0.4525891752124281 and parameters: {'n_estimators': 116, 'max_features': 0.48631416204186984, 'min_samples_split': 16, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:21:55,727] Trial 16 finished with value: 0.5258770703348516 and parameters: {'n_estimators': 77, 'max_features': 0.8728582941280343, 'min_samples_split': 17, 'min_samples_leaf': 12}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:23:34,113] Trial 17 finished with value: 0.4724919595697238 and parameters: {'n_estimators': 131, 'max_features': 0.7402879798813459, 'min_samples_split': 14, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.4283603156422992.\n",
      "[I 2023-07-27 23:25:38,637] Trial 18 finished with value: 0.39967156754906985 and parameters: {'n_estimators': 105, 'max_features': 0.9940598404788931, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:27:51,917] Trial 19 finished with value: 0.40877981033934085 and parameters: {'n_estimators': 162, 'max_features': 0.6592253525694732, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:30:20,964] Trial 20 finished with value: 0.5115223325748257 and parameters: {'n_estimators': 163, 'max_features': 0.9941567358731273, 'min_samples_split': 6, 'min_samples_leaf': 11}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:31:56,490] Trial 21 finished with value: 0.4119751285471051 and parameters: {'n_estimators': 111, 'max_features': 0.6946921280591271, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:34:52,933] Trial 22 finished with value: 0.4084026010198835 and parameters: {'n_estimators': 171, 'max_features': 0.8740033751536321, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:37:26,713] Trial 23 finished with value: 0.4217930852944175 and parameters: {'n_estimators': 163, 'max_features': 0.8314595656326483, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:40:40,209] Trial 24 finished with value: 0.4028140473354231 and parameters: {'n_estimators': 170, 'max_features': 0.8832009588185255, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:43:45,322] Trial 25 finished with value: 0.4521170957613646 and parameters: {'n_estimators': 198, 'max_features': 0.8945684734719794, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:46:18,729] Trial 26 finished with value: 0.48014005471452686 and parameters: {'n_estimators': 175, 'max_features': 0.8771577926462497, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:48:04,651] Trial 27 finished with value: 0.5380934927447295 and parameters: {'n_estimators': 129, 'max_features': 0.9590209922749617, 'min_samples_split': 5, 'min_samples_leaf': 14}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:50:03,936] Trial 28 finished with value: 0.5021248111669421 and parameters: {'n_estimators': 134, 'max_features': 0.9980227758076572, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:52:36,386] Trial 29 finished with value: 0.4447113111653471 and parameters: {'n_estimators': 171, 'max_features': 0.8364917144738448, 'min_samples_split': 13, 'min_samples_leaf': 5}. Best is trial 18 with value: 0.39967156754906985.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 23:55:34,105] Trial 30 finished with value: 0.4049853554521093 and parameters: {'n_estimators': 190, 'max_features': 0.7635461430223787, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-27 23:58:29,394] Trial 31 finished with value: 0.40495668544940405 and parameters: {'n_estimators': 189, 'max_features': 0.7727331858917112, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-28 00:01:35,294] Trial 32 finished with value: 0.4088810380964872 and parameters: {'n_estimators': 200, 'max_features': 0.7613486857785191, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 18 with value: 0.39967156754906985.\n",
      "[I 2023-07-28 00:04:52,948] Trial 33 finished with value: 0.39162938785445806 and parameters: {'n_estimators': 187, 'max_features': 0.788667861354926, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.39162938785445806.\n",
      "[I 2023-07-28 00:08:27,835] Trial 34 finished with value: 0.4370274179196481 and parameters: {'n_estimators': 184, 'max_features': 0.9326035506779295, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 33 with value: 0.39162938785445806.\n",
      "[I 2023-07-28 00:13:01,548] Trial 35 finished with value: 0.3851400717844094 and parameters: {'n_estimators': 194, 'max_features': 0.8168223956908495, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 35 with value: 0.3851400717844094.\n",
      "[I 2023-07-28 00:15:10,456] Trial 36 finished with value: 0.49238004323801965 and parameters: {'n_estimators': 157, 'max_features': 0.9097818152810176, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 35 with value: 0.3851400717844094.\n",
      "[I 2023-07-28 00:18:07,272] Trial 37 finished with value: 0.4211713911736291 and parameters: {'n_estimators': 193, 'max_features': 0.8625204247359383, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 35 with value: 0.3851400717844094.\n",
      "[I 2023-07-28 00:20:23,045] Trial 38 finished with value: 0.4687992415542359 and parameters: {'n_estimators': 176, 'max_features': 0.8188643818183757, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 35 with value: 0.3851400717844094.\n",
      "[I 2023-07-28 00:23:04,632] Trial 39 finished with value: 0.3879670942569582 and parameters: {'n_estimators': 140, 'max_features': 0.941895647368676, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 35 with value: 0.3851400717844094.\n",
      "[I 2023-07-28 00:25:24,159] Trial 40 finished with value: 0.3781654916666235 and parameters: {'n_estimators': 85, 'max_features': 0.9427045663691906, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.3781654916666235.\n",
      "[I 2023-07-28 00:27:37,567] Trial 41 finished with value: 0.3781654916666235 and parameters: {'n_estimators': 85, 'max_features': 0.9577419982636743, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.3781654916666235.\n",
      "[I 2023-07-28 00:29:51,630] Trial 42 finished with value: 0.3782257649284101 and parameters: {'n_estimators': 84, 'max_features': 0.9460917639705569, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.3781654916666235.\n",
      "[I 2023-07-28 00:32:26,719] Trial 43 finished with value: 0.3784165491168595 and parameters: {'n_estimators': 76, 'max_features': 0.9467734368095291, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.3781654916666235.\n",
      "[I 2023-07-28 00:34:59,064] Trial 44 finished with value: 0.3784404890734723 and parameters: {'n_estimators': 73, 'max_features': 0.9521900892713858, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.3781654916666235.\n",
      "[I 2023-07-28 00:37:14,458] Trial 45 finished with value: 0.37850711717038854 and parameters: {'n_estimators': 72, 'max_features': 0.9537303211991248, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 40 with value: 0.3781654916666235.\n",
      "[I 2023-07-28 00:39:13,022] Trial 46 finished with value: 0.3776943679329494 and parameters: {'n_estimators': 84, 'max_features': 0.9087549035601571, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 46 with value: 0.3776943679329494.\n",
      "[I 2023-07-28 00:41:16,934] Trial 47 finished with value: 0.37745043645281606 and parameters: {'n_estimators': 91, 'max_features': 0.9136549104184549, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:42:21,495] Trial 48 finished with value: 0.5498363654122616 and parameters: {'n_estimators': 88, 'max_features': 0.90516530714129, 'min_samples_split': 3, 'min_samples_leaf': 15}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:43:46,413] Trial 49 finished with value: 0.42119025631389373 and parameters: {'n_estimators': 87, 'max_features': 0.9106104731260481, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:44:47,208] Trial 50 finished with value: 0.43734659911712725 and parameters: {'n_estimators': 64, 'max_features': 0.9705447318187769, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:46:51,186] Trial 51 finished with value: 0.3783108333695347 and parameters: {'n_estimators': 81, 'max_features': 0.9332861244530495, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:48:31,087] Trial 52 finished with value: 0.37879230015542315 and parameters: {'n_estimators': 83, 'max_features': 0.8589736901169266, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:50:37,063] Trial 53 finished with value: 0.3778515779434237 and parameters: {'n_estimators': 97, 'max_features': 0.9199360767401042, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:51:39,419] Trial 54 finished with value: 0.4027961585245786 and parameters: {'n_estimators': 96, 'max_features': 0.9994644095507588, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:52:42,848] Trial 55 finished with value: 0.37853844517494833 and parameters: {'n_estimators': 66, 'max_features': 0.9062417446783628, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:53:42,583] Trial 56 finished with value: 0.4218311364866948 and parameters: {'n_estimators': 94, 'max_features': 0.8494556679976625, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:54:23,989] Trial 57 finished with value: 0.3873294744465244 and parameters: {'n_estimators': 53, 'max_features': 0.9063224312344359, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:55:54,246] Trial 58 finished with value: 0.40231563684332816 and parameters: {'n_estimators': 114, 'max_features': 0.9643057037164772, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:57:18,661] Trial 59 finished with value: 0.37820447762146736 and parameters: {'n_estimators': 103, 'max_features': 0.8503936151650993, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:58:07,614] Trial 60 finished with value: 0.5751558838120181 and parameters: {'n_estimators': 104, 'max_features': 0.8516361360988427, 'min_samples_split': 4, 'min_samples_leaf': 18}. Best is trial 47 with value: 0.37745043645281606.\n",
      "[I 2023-07-28 00:59:31,346] Trial 61 finished with value: 0.37743483953692397 and parameters: {'n_estimators': 92, 'max_features': 0.8866520738712198, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 61 with value: 0.37743483953692397.\n",
      "[I 2023-07-28 01:00:38,364] Trial 62 finished with value: 0.38620958221064133 and parameters: {'n_estimators': 93, 'max_features': 0.8833411243084729, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 61 with value: 0.37743483953692397.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "# train.csv 파일 불러오기\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# '월'과 '일'을 결합하여 '월일' 변수 생성\n",
    "train_data['월일'] = train_data['월'].astype(str) + '-' + train_data['일'].astype(str)\n",
    "\n",
    "# '월일' 열을 datetime 형식으로 변환하며, 변환 중 오류가 발생하면 처리\n",
    "def convert_to_nearest_valid_date(x):\n",
    "    try:\n",
    "        return pd.to_datetime(x, format='%m-%d')\n",
    "    except ValueError:\n",
    "        month, day = x.split('-')\n",
    "        month, day = int(month), int(day)\n",
    "        max_day_in_month = np.clip(day, 1, 28)  # Clip day to be within a valid range (1 to 28)\n",
    "        return pd.to_datetime(f'2022-{month:02d}-{max_day_in_month:02d}')\n",
    "\n",
    "train_data['월일'] = train_data['월일'].apply(convert_to_nearest_valid_date)\n",
    "\n",
    "\n",
    "# 1월 1일로부터 며칠이 지났는지 일 수를 센 값으로 변경\n",
    "train_data['일_수'] = train_data['월일'] - pd.to_datetime('01-01', format='%m-%d')\n",
    "train_data['일_수'] = train_data['일_수'].dt.days\n",
    "\n",
    "# '일 수' 값을 365로 나누어 새로운 변수 '일_수_정규화' 생성\n",
    "train_data['일_수_정규화'] = train_data['일_수'] % 365\n",
    "\n",
    "# '일 수_정규화' 변수를 sin, cos 함수를 활용하여 주기성을 나타내는 두 개의 새로운 변수 생성\n",
    "train_data['월일_sin'] = np.sin(2 * np.pi * train_data['일_수_정규화'] / 365)\n",
    "train_data['월일_cos'] = np.cos(2 * np.pi * train_data['일_수_정규화'] / 365)\n",
    "\n",
    "# '월일' 열은 더 이상 필요 없으므로 삭제\n",
    "train_data.drop(['월일'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# '측정 시간대'를 시간대로 변환하는 함수 생성\n",
    "def time_to_hour_category(time_str):\n",
    "    if '새벽' in time_str:\n",
    "        return 0  # 새벽\n",
    "    elif '오전' in time_str:\n",
    "        return 6  # 오전\n",
    "    elif '오후' in time_str:\n",
    "        return 12  # 오후\n",
    "    elif '저녁' in time_str:\n",
    "        return 18  # 저녁\n",
    "    else:\n",
    "        return None  # 그 외의 경우 (예: 결측치)\n",
    "\n",
    "# '측정 시간대' 컬럼을 시간대로 변환하여 새로운 컬럼 '시간대' 생성\n",
    "train_data['시간대'] = train_data['측정 시간대'].apply(time_to_hour_category)\n",
    "\n",
    "# 변환에 사용되지 않을 '측정 시간대' 컬럼을 삭제\n",
    "train_data.drop(['측정 시간대'], axis=1, inplace=True)\n",
    "\n",
    "# '월'을 기반으로 '계절' 더미 열 생성 함수\n",
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return '봄'\n",
    "    elif 6 <= month <= 8:\n",
    "        return '여름'\n",
    "    elif 9 <= month <= 11:\n",
    "        return '가을'\n",
    "    else:\n",
    "        return '겨울'\n",
    "# '월' 정보를 바탕으로 '계절' 더미 열 생성\n",
    "train_data['계절'] = train_data['월'].apply(get_season)\n",
    "# One-Hot Encoding을 활용하여 '계절' 더미 열을 변환\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "train_season_encoded = pd.DataFrame(ohe.fit_transform(train_data[['계절']]), columns=ohe.get_feature_names(['계절']))\n",
    "# 기존 데이터와 '계절' 더미 열을 합칩니다.\n",
    "train_data = pd.concat([train_data, train_season_encoded], axis=1)\n",
    "# 더미 열로 변환된 '계절' 컬럼과 원래의 '계절' 컬럼을 삭제합니다.\n",
    "train_data.drop(['계절'], axis=1, inplace=True)\n",
    "\n",
    "# 결측치를 평균값으로 대체\n",
    "train_data = train_data.fillna(train_data.mean())\n",
    "\n",
    "# 풍속을 예측할 특성(입력 변수)과 풍속(출력 변수)을 분리합니다.\n",
    "X_train = train_data.drop(['ID', '풍속 (m/s)'], axis=1)  # 입력 변수들\n",
    "y_train = train_data['풍속 (m/s)']  # 출력 변수 (풍속)\n",
    "\n",
    "# test.csv 파일 불러오기\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# '월'과 '일'을 결합하여 '월일' 변수 생성\n",
    "test_data['월일'] = test_data['월'].astype(str) + '-' + test_data['일'].astype(str)\n",
    "\n",
    "# '월일' 열을 datetime 형식으로 변환하며, 변환 중 오류가 발생하면 가장 가까운 날짜로 처리\n",
    "test_data['월일'] = test_data['월일'].apply(convert_to_nearest_valid_date)\n",
    "\n",
    "# 1월 1일로부터 며칠이 지났는지 일 수를 센 값으로 변경\n",
    "test_data['일_수'] = test_data['월일'] - pd.to_datetime('01-01', format='%m-%d')\n",
    "test_data['일_수'] = test_data['일_수'].dt.days\n",
    "\n",
    "# '일 수' 값을 365로 나누어 새로운 변수 '일_수_정규화' 생성\n",
    "test_data['일_수_정규화'] = test_data['일_수'] % 365\n",
    "\n",
    "# '일 수_정규화' 변수를 sin, cos 함수를 활용하여 주기성을 나타내는 두 개의 새로운 변수 생성\n",
    "test_data['월일_sin'] = np.sin(2 * np.pi * train_data['일_수_정규화'] / 365)\n",
    "test_data['월일_cos'] = np.cos(2 * np.pi * train_data['일_수_정규화'] / 365)\n",
    "\n",
    "# '월일' 열은 더 이상 필요 없으므로 삭제\n",
    "test_data.drop(['월일'], axis=1, inplace=True)\n",
    "\n",
    "# '측정 시간대' 컬럼을 시간대로 변환하여 새로운 컬럼 '시간대' 생성\n",
    "test_data['시간대'] = test_data['측정 시간대'].apply(time_to_hour_category)\n",
    "\n",
    "# 변환에 사용되지 않을 '측정 시간대' 컬럼을 삭제\n",
    "test_data.drop(['측정 시간대'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#'시간대' 변수를 sin, cos 함수를 활용하여 주기성을 나타내는 두 개의 새로운 변수를 생성합니다.\n",
    "\n",
    "train_data['시간대_sin'] = np.sin(2 * np.pi * train_data['시간대'] / 24)\n",
    "train_data['시간대_cos'] = np.cos(2 * np.pi * train_data['시간대'] / 24)\n",
    "\n",
    "test_data['시간대_sin'] = np.sin(2 * np.pi * test_data['시간대'] / 24)\n",
    "test_data['시간대_cos'] = np.cos(2 * np.pi * test_data['시간대'] / 24)\n",
    "\n",
    "# '월' 정보를 바탕으로 '계절' 더미 열 생성\n",
    "test_data['계절'] = test_data['월'].apply(get_season)\n",
    "\n",
    "# One-Hot Encoding을 활용하여 '계절' 더미 열을 변환\n",
    "test_season_encoded = pd.DataFrame(ohe.transform(test_data[['계절']]), columns=ohe.get_feature_names(['계절']))\n",
    "\n",
    "# 기존 데이터와 '계절' 더미 열을 합칩니다.\n",
    "test_data = pd.concat([test_data, test_season_encoded], axis=1)\n",
    "\n",
    "# 더미 열로 변환된 '계절' 컬럼과 원래의 '계절' 컬럼을 삭제합니다.\n",
    "test_data.drop(['계절'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# 결측치를 평균값으로 대체\n",
    "test_data = test_data.fillna(test_data.mean())\n",
    "\n",
    "X_test = test_data.drop('ID', axis=1)  # 테스트 입력 변수들\n",
    "\n",
    "# 함수 정의: Optuna를 활용한 하이퍼파라미터 최적화\n",
    "def objective(trial):\n",
    "    # ExtraTreesRegressor의 하이퍼파라미터 탐색 범위를 지정합니다.\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    max_features = trial.suggest_float(\"max_features\", 0.1, 1.0)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
    "\n",
    "    # ExtraTreesRegressor 모델을 정의합니다.\n",
    "    model = ExtraTreesRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Cross Validation으로 모델 평가 (MAE를 평가 지표로 사용합니다.)\n",
    "    mae_scores = -cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=5)\n",
    "    mean_mae = np.mean(mae_scores)\n",
    "    return mean_mae\n",
    "\n",
    "# 풍속을 예측할 특성(입력 변수)과 풍속(출력 변수)을 분리합니다.\n",
    "X_train = train_data.drop(['ID', '풍속 (m/s)'], axis=1)  # 입력 변수들\n",
    "y_train = train_data['풍속 (m/s)']  # 출력 변수 (풍속)\n",
    "\n",
    "# Optuna를 활용한 하이퍼파라미터 최적화\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 최적 하이퍼파라미터 값을 가져옵니다.\n",
    "best_params = study.best_params\n",
    "\n",
    "# 최적화된 하이퍼파라미터로 모델을 재학습합니다.\n",
    "best_model = ExtraTreesRegressor(\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    max_features=best_params[\"max_features\"],\n",
    "    min_samples_split=best_params[\"min_samples_split\"],\n",
    "    min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 풍속 예측을 수행합니다.\n",
    "y_pred = best_model.predict(X_test)  # 테스트 데이터로 풍속 예측\n",
    "\n",
    "# Submit / 제출\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "# 풍속 예측 결과를 '풍속 (m/s)' 열에 대입합니다.\n",
    "submission['풍속 (m/s)'] = y_pred\n",
    "\n",
    "# 예측 결과를 submission.csv 양식에 맞게 저장합니다.\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"풍속 예측이 완료되었습니다. 결과가 submission.csv에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "# Cross Validation을 활용하여 평균 MAE 계산\n",
    "mae_scores = -cross_val_score(best_model, X_train, y_train, scoring='neg_mean_absolute_error', cv=5)\n",
    "print(\"평균 MAE:\", np.mean(mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4c2e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
