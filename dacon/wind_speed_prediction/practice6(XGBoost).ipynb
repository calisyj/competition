{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb506bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \n",
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "[I 2023-07-24 12:38:43,642] A new study created in memory with name: no-name-69df8848-adb7-484d-bec6-228de44de43f\n",
      "[I 2023-07-24 12:39:21,554] Trial 0 finished with value: 1.0307959374072886 and parameters: {'n_estimators': 243, 'max_depth': 3, 'learning_rate': 0.042990257767997093, 'subsample': 0.788210115449548, 'colsample_bytree': 0.7733429689103928}. Best is trial 0 with value: 1.0307959374072886.\n",
      "[I 2023-07-24 12:41:11,770] Trial 1 finished with value: 0.6516804565408565 and parameters: {'n_estimators': 172, 'max_depth': 11, 'learning_rate': 0.01966469162451124, 'subsample': 0.8516739396334921, 'colsample_bytree': 0.9087671790346366}. Best is trial 1 with value: 0.6516804565408565.\n",
      "[I 2023-07-24 12:43:34,093] Trial 2 finished with value: 0.9069186595143041 and parameters: {'n_estimators': 842, 'max_depth': 3, 'learning_rate': 0.043455940133852296, 'subsample': 0.6547525003943131, 'colsample_bytree': 0.8401426167578367}. Best is trial 1 with value: 0.6516804565408565.\n",
      "[I 2023-07-24 12:50:47,988] Trial 3 finished with value: 0.5709847050979879 and parameters: {'n_estimators': 570, 'max_depth': 14, 'learning_rate': 0.05660372328642928, 'subsample': 0.7387240446997481, 'colsample_bytree': 0.5615495210226261}. Best is trial 3 with value: 0.5709847050979879.\n",
      "[I 2023-07-24 12:52:38,742] Trial 4 finished with value: 1.0909525573875267 and parameters: {'n_estimators': 618, 'max_depth': 4, 'learning_rate': 0.0049321226418997015, 'subsample': 0.8237499765803884, 'colsample_bytree': 0.5787485822603934}. Best is trial 3 with value: 0.5709847050979879.\n",
      "[I 2023-07-24 12:59:44,015] Trial 5 finished with value: 0.5593998038582573 and parameters: {'n_estimators': 599, 'max_depth': 15, 'learning_rate': 0.04260252840055961, 'subsample': 0.8272655081985699, 'colsample_bytree': 0.6819296412578897}. Best is trial 5 with value: 0.5593998038582573.\n",
      "[I 2023-07-24 13:01:24,230] Trial 6 finished with value: 0.7232823930982425 and parameters: {'n_estimators': 130, 'max_depth': 11, 'learning_rate': 0.018493067451791363, 'subsample': 0.6100424413478955, 'colsample_bytree': 0.836909467243537}. Best is trial 5 with value: 0.5593998038582573.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# train.csv 파일 불러오기\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# 결측치를 평균값으로 대체\n",
    "train_data = train_data.fillna(train_data.mean())\n",
    "\n",
    "# '측정 시간대'를 원핫 인코딩하여 숫자 형태로 변환\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "time_encoded = encoder.fit_transform(train_data[['측정 시간대']])\n",
    "time_encoded_df = pd.DataFrame(time_encoded, columns=encoder.get_feature_names(['측정 시간대']))\n",
    "train_data = pd.concat([train_data, time_encoded_df], axis=1).drop(['측정 시간대'], axis=1)\n",
    "\n",
    "# 풍속을 예측할 특성(입력 변수)과 풍속(출력 변수)을 분리합니다.\n",
    "X_train = train_data.drop(['ID', '풍속 (m/s)'], axis=1)  # 입력 변수들\n",
    "y_train = train_data['풍속 (m/s)']  # 출력 변수 (풍속)\n",
    "\n",
    "# optuna를 활용한 하이퍼파라미터 최적화 (RandomForestRegressor 대신 XGBoost로 변경)\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "\n",
    "    # XGBoostRegressor 모델 생성\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Cross Validation을 활용하여 평균 RMSE 계산\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    \n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "# optuna를 활용한 하이퍼파라미터 최적화\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('  Value: ', trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n",
    "\n",
    "# 최적의 하이퍼파라미터로 XGBoostRegressor 모델 생성\n",
    "best_xg_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=study.best_params['n_estimators'],\n",
    "    max_depth=study.best_params['max_depth'],\n",
    "    learning_rate=study.best_params['learning_rate'],\n",
    "    subsample=study.best_params['subsample'],\n",
    "    colsample_bytree=study.best_params['colsample_bytree'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 보팅 앙상블 모델 생성 (RandomForestRegressor 대신 XGBoost로 변경)\n",
    "ensemble_model = VotingRegressor(estimators=[('xg', best_xg_model), ('rf', best_rf_model)], n_jobs=-1)\n",
    "\n",
    "# 스태킹을 위한 모델 생성 (RandomForestRegressor 대신 XGBoost로 변경)\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[('xg', best_xg_model), ('rf', best_rf_model)],\n",
    "    final_estimator=best_xg_model\n",
    ")\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# 스태킹 모델 학습\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# test.csv 파일 불러오기\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# 결측치를 평균값으로 대체\n",
    "test_data = test_data.fillna(test_data.mean())\n",
    "\n",
    "# '측정 시간대'를 원핫 인코딩하여 숫자 형태로 변환\n",
    "time_encoded = encoder.transform(test_data[['측정 시간대']])\n",
    "time_encoded_df = pd.DataFrame(time_encoded, columns=encoder.get_feature_names(['측정 시간대']))\n",
    "test_data = pd.concat([test_data, time_encoded_df], axis=1).drop(['측정 시간대'], axis=1)\n",
    "\n",
    "# 테스트 데이터로 예측을 수행합니다.\n",
    "X_test = test_data.drop('ID', axis=1)  # 테스트 입력 변수들\n",
    "\n",
    "# 앙상블 모델 예측\n",
    "ensemble_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# 스태킹 모델 예측\n",
    "stacking_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# 앙상블 결과와 스태킹 결과를 평균하여 최종 예측값 도출\n",
    "final_pred = (ensemble_pred + stacking_pred) / 2\n",
    "\n",
    "# Submit / 제출\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['풍속 (m/s)'] = final_pred\n",
    "\n",
    "# 예측 결과를 submission.csv 양식에 맞게 저장합니다.\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"풍속 예측이 완료되었습니다. 결과가 submission.csv에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254fff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation을 활용하여 평균 RMSE 계산\n",
    "scores = cross_val_score(ensemble_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"평균 RMSE:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation을 활용하여 평균 RMSE 계산\n",
    "scores = cross_val_score(stacking_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"평균 RMSE:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013c6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
