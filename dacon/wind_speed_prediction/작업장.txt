0.3897885014600465(extra regressor)
0.38825477079960924(extra regressor + optuna)
0.3876383823014374(extra regressor + feature engineering(시간대))
0.37738423261646503((extra regressor + feature engineering(시간대 주기성+월일 주기성))) : 과적합
0.37646408230778133((extra regressor + feature engineering(시간대 주기성+월일 주기성+계절)) : 과적합
0.375682554927087 ((optuna + feature engineering(시간대 주기성+월일 주기성)))
0.3280204350465884((tpot + feature engineering(시간대 주기성+월일 주기성))) : 과적합 tpot은 과적합을 잡아주지 않는듯.


caret
비선형 변환(데이터 패턴 더 잘 표현)
구간화(노이즈 줄임)
주기성 변수

<수행해본 모델> (0 extraregression 1 radom forest , 2 neural network regrssion  3 catboost 4 lightgbm )
선형 회귀 (Linear Regression): 선형 관계를 모델링하는 가장 기본적인 회귀 알고리즘입니다. 모델의 가중치와 편향을 최적화하여 예측을 수행합니다. 비교적 간단하고 해석하기 쉬운 모델이지만, 비선형적인 관계를 모델링하기 어려울 수 있습니다.

의사결정트리 회귀 (Decision Tree Regression): 트리 구조로 데이터를 분할하여 예측을 수행하는 알고리즘입니다. 데이터를 잘 나누어주는 속성과 임계값을 학습하여 예측합니다. 해석력이 좋고 비선형적인 데이터를 모델링할 수 있습니다.

랜덤 포레스트 회귀 (Random Forest Regression): 여러 개의 의사결정트리를 앙상블하여 예측을 수행하는 알고리즘입니다. 트리의 다양성으로 과적합을 줄이고, 안정적인 예측 성능을 제공합니다.

그래디언트 부스팅 회귀 (Gradient Boosting Regression): 약한 예측 모델을 순차적으로 학습시켜 성능을 향상시키는 알고리즘입니다. 잔차에 대한 그래디언트를 이용하여 모델을 업데이트하고, 강력한 예측 성능을 제공합니다.

신경망 기반 회귀 (Neural Network Regression): 딥러닝 기반의 다층 신경망을 사용하여 예측을 수행하는 알고리즘입니다. 복잡한 데이터 패턴을 학습할 수 있으며, 대용량 데이터에 적합합니다.

Ridge 회귀 (Ridge Regression):

Ridge 회귀는 선형 회귀 모델의 한 종류로, L2 규제를 추가하여 가중치의 크기를 제한하는 방법입니다. 이를 통해 과적합을 줄이고 모델의 일반화 성능을 향상시킬 수 있습니다.
Lasso 회귀 (Lasso Regression):

Lasso 회귀도 선형 회귀 모델의 한 종류로, L1 규제를 추가하여 가중치의 크기를 제한하는 방법입니다. Lasso 회귀는 일부 계수를 0으로 만들어 특성 선택의 효과를 가지며, 특성 선택과 모델의 복잡성을 동시에 해결할 수 있습니다.
Elastic Net 회귀 (Elastic Net Regression):

Elastic Net 회귀는 L2 규제와 L1 규제를 혼합한 모델로, Ridge와 Lasso 회귀의 특성을 결합한 모델입니다. L1 규제와 L2 규제의 비율을 조절하여 모델을 조정할 수 있습니다.
Bayesian Ridge 회귀 (Bayesian Ridge Regression):

Bayesian Ridge 회귀는 선형 회귀 모델의 한 종류로, 베이지안 접근법을 사용하여 가중치와 오차를 추정하는 방법입니다. 데이터에 대한 사전 정보를 반영하여 회귀 모델을 구축합니다.
Support Vector Regression (SVR):

SVR은 서포트 벡터 머신(SVM)을 회귀 분석에 적용한 방법입니다. SVM의 아이디어를 회귀에 적용하여 비선형 회귀 문제를 해결할 수 있습니다.
K-최근접 이웃 회귀 (K-Nearest Neighbors Regression):

K-최근접 이웃 회귀는 주어진 데이터 포인트의 근접 이웃들의 출력 변수의 평균을 사용하여 예측하는 회귀 모델입니다. 주변 데이터의 값에 따라 예측을 수행합니다.
Decision Forest 회귀:

Decision Forest 회귀는 여러 개의 결정 트리를 사용하여 회귀 모델을 형성하는 방법입니다. 여러 결정 트리의 예측 결과를 평균하여 회귀 결과를 얻습니다.
XGBoost 회귀 (Extreme Gradient Boosting Regression):

XGBoost 회귀는 그래디언트 부스팅의 변형으로, 다수의 결정 트리를 앙상블하여 회귀 모델을 구성합니다. 속도와 성능 면에서 우수한 알고리즘 중 하나입니다.
LightGBM 회귀 (Light Gradient Boosting Regression):

LightGBM 회귀는 그래디언트 부스팅의 변형으로, XGBoost와 유사하게 다수의 결정 트리를 앙상블하여 회귀 모델을 구성합니다. 대용량 데이터에서 빠른 학습과 예측이 가능합니다.
CatBoost 회귀:

CatBoost 회귀는 그래디언트 부스팅의 변형으로, 범주형 변수를 자동으로 처리할 수 있는 특징을 가지고 있습니다. 범주형 변수를 원-핫 인코딩하지 않고도 쉽게 학습할 수 있습니다.
Huber 회귀 (Huber Regression):

Huber 회귀는 회귀 분석에서 이상치에 강건한 특성을 가진 회귀 모델입니다. 평균 절댓값 오차와 평균 제곱 오차의 혼합 함수를 최소화하는 방법으로 학습합니다.



그래디언트 부스팅 회귀 (Gradient Boosting Regressor): 랜덤 포레스트와 비슷한 앙상블 학습 방법입니다. 여러 약한 학습기(일반적으로 의사결정트리)를 순차적으로 구축하며 각 트리는 이전 트리의 오차를 보정합니다. sklearn.ensemble.GradientBoostingRegressor이 이 모델을 구현한 예입니다.

에이다부스트 회귀 (AdaBoost Regressor): 에이다부스트는 약한 학습기를 결합하여 강력한 학습기를 만드는 앙상블 학습 기법입니다. 어려운 케이스에 초점을 맞추기 위해 오분류된 샘플의 가중치를 반복적으로 조정합니다. sklearn.ensemble.AdaBoostRegressor가 회귀 작업용 에이다부스트의 구현입니다.
칙을 만듭니다. sklearn.tree.DecisionTreeRegressor가 결정 트리 회귀의 구현입니다.

엑스트라 트리 회귀 (Extra Trees Regressor): 이는 랜덤 포레스트의 다른 변형으로, 최적 분할을 찾는 대신 무작위 분할을 사용하여 속도를 높이지만 분산이 높아질 수 있습니다. sklearn.ensemble.ExtraTreesRegressor가 이 모델의 구현입니다.

1 섭씨 온도(°⁣C)
2 절대 온도(K)
3 이슬점 온도(°C)
4 상대 습도 (%) .
5 대기압(mbar) .
6 포화 증기압(mbar)
7 실제 증기압(mbar)
8 증기압 부족량(mbar)
9 수증기 함량 (g/kg)
10 공기 밀도 (g/m**3) .
11 풍향 (deg)
12 풍속 (m/s)

'측정 시간대_새벽', '측정 시간대_오전', '측정 시간대_오후', '측정 시간대_저녁'
'섭씨온도*절대온도*이슬점온도*포화증기압'
'섭씨온도*절대온도*이슬점온도*실제증기압'
'섭씨온도*절대온도*이슬점온도*증기압부족량'
'섭씨온도*절대온도*이슬점온도*수증기함량'
'상대습도*공기밀도'
'실제증기압*수증기함량'
'공기밀도*대기압'

1. 섭씨온도, 절대온도, 이슬점 온도
포화 증기압
실제 증기압
증기압 부족량
수증기함량

2. 상대습도
공기밀도

3. 실제증기압
수증기함량

4. 공기밀도
대기압


살충제 성분을 공기 중으로 퍼트리는 형태.

https://dacon.io/codeshare/7721


Feature Engineering을 수행하는 방법은 다양합니다. 일반적으로 다음과 같은 기법들이 사용됩니다:

새로운 변수 생성: 기존 변수들의 조합이나 비율을 이용하여 새로운 변수를 생성합니다. 예를 들어, 두 변수의 합, 차이, 곱, 나눗셈을 이용하여 새로운 변수를 만들 수 있습니다.

비선형 변환: 변수에 로그, 제곱근, 지수 등의 비선형 변환을 적용하여 데이터의 패턴을 더 잘 표현할 수 있도록 합니다.

주기성 변수: 시계열 데이터나 계절성을 가지는 데이터에서 주기성을 반영하는 변수를 생성합니다. 주기성을 나타내는 사인 함수나 코사인 함수 등을 사용할 수 있습니다.

구간화: 연속형 변수를 구간으로 나누어 범주형 변수로 변환합니다. 이는 모델에 노이즈를 줄이고 비선형성을 처리하는 데 도움을 줄 수 있습니다.

상호작용 변수: 두 변수의 곱이나 합 등의 상호작용을 나타내는 변수를 생성하여 모델에 추가합니다.

