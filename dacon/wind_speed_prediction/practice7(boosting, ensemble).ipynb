{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0a2909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "[I 2023-07-24 14:06:21,451] A new study created in memory with name: no-name-1c645af7-5e3b-46ac-8080-4196589b87be\n",
      "[I 2023-07-24 14:06:29,169] Trial 0 finished with value: 0.737958583262305 and parameters: {'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.7, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 0 with value: 0.737958583262305.\n",
      "[I 2023-07-24 14:06:35,805] Trial 1 finished with value: 0.0013268305011300495 and parameters: {'n_estimators': 50, 'learning_rate': 0.01, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 0 with value: 0.737958583262305.\n",
      "[I 2023-07-24 14:06:59,569] Trial 2 finished with value: 0.8310591966497588 and parameters: {'n_estimators': 300, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 2 with value: 0.8310591966497588.\n",
      "[I 2023-07-24 14:07:20,383] Trial 3 finished with value: 0.8257604791623123 and parameters: {'n_estimators': 200, 'learning_rate': 0.3, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 2 with value: 0.8310591966497588.\n",
      "[I 2023-07-24 14:07:41,995] Trial 4 finished with value: 0.5637824659801188 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 2 with value: 0.8310591966497588.\n",
      "[I 2023-07-24 14:07:55,442] Trial 5 finished with value: 0.5074630363781257 and parameters: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 2 with value: 0.8310591966497588.\n",
      "[I 2023-07-24 14:08:14,686] Trial 6 finished with value: 0.7590168532209789 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 2 with value: 0.8310591966497588.\n",
      "[I 2023-07-24 14:08:25,130] Trial 7 finished with value: 0.495648930465631 and parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.7, 'colsample_bytree': 0.6, 'random_state': 42}. Best is trial 2 with value: 0.8310591966497588.\n",
      "[I 2023-07-24 14:08:27,216] Trial 8 finished with value: 0.5518590101409393 and parameters: {'n_estimators': 50, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 2 with value: 0.8310591966497588.\n",
      "[I 2023-07-24 14:08:45,222] Trial 9 finished with value: 0.7155574648390189 and parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 2 with value: 0.8310591966497588.\n",
      "[I 2023-07-24 14:09:26,073] Trial 10 finished with value: 0.8315669092460609 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 10 with value: 0.8315669092460609.\n",
      "[I 2023-07-24 14:10:08,121] Trial 11 finished with value: 0.8315669092460609 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 10 with value: 0.8315669092460609.\n",
      "[I 2023-07-24 14:10:42,410] Trial 12 finished with value: 0.8120525750154627 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 10 with value: 0.8315669092460609.\n",
      "[I 2023-07-24 14:11:23,612] Trial 13 finished with value: 0.8264187246978268 and parameters: {'n_estimators': 400, 'learning_rate': 0.15, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 10 with value: 0.8315669092460609.\n",
      "[I 2023-07-24 14:12:05,513] Trial 14 finished with value: 0.8311830896455094 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.9, 'colsample_bytree': 0.6, 'random_state': 42}. Best is trial 10 with value: 0.8315669092460609.\n",
      "[I 2023-07-24 14:13:04,298] Trial 15 finished with value: 0.8391426118956213 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 15 with value: 0.8391426118956213.\n",
      "[I 2023-07-24 14:14:03,016] Trial 16 finished with value: 0.8391426118956213 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 15 with value: 0.8391426118956213.\n",
      "[I 2023-07-24 14:15:15,882] Trial 17 finished with value: 0.8464738097445752 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 17 with value: 0.8464738097445752.\n",
      "[I 2023-07-24 14:16:41,370] Trial 18 finished with value: 0.8452581634173795 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 17 with value: 0.8464738097445752.\n",
      "[I 2023-07-24 14:18:08,608] Trial 19 finished with value: 0.8444358178473479 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 17 with value: 0.8464738097445752.\n",
      "[I 2023-07-24 14:19:35,275] Trial 20 finished with value: 0.8481755455211719 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 20 with value: 0.8481755455211719.\n",
      "[I 2023-07-24 14:21:02,952] Trial 21 finished with value: 0.8481755455211719 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 20 with value: 0.8481755455211719.\n",
      "[I 2023-07-24 14:22:29,664] Trial 22 finished with value: 0.8481755455211719 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 20 with value: 0.8481755455211719.\n",
      "[I 2023-07-24 14:23:55,611] Trial 23 finished with value: 0.8481755455211719 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 20 with value: 0.8481755455211719.\n",
      "[I 2023-07-24 14:25:23,401] Trial 24 finished with value: 0.8481755455211719 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 20 with value: 0.8481755455211719.\n",
      "[I 2023-07-24 14:27:01,006] Trial 25 finished with value: 0.8522855362829478 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 25 with value: 0.8522855362829478.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 14:27:22,570] Trial 26 finished with value: 0.8368111555134087 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 25 with value: 0.8522855362829478.\n",
      "[I 2023-07-24 14:29:13,656] Trial 27 finished with value: 0.8538789662783184 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:31:17,071] Trial 28 finished with value: 0.8538789662783184 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:31:37,997] Trial 29 finished with value: 0.8187478265616001 and parameters: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7, 'colsample_bytree': 0.6, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:33:31,551] Trial 30 finished with value: 0.8493884420995446 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:35:43,581] Trial 31 finished with value: 0.8493884420995446 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:37:53,020] Trial 32 finished with value: 0.8493884420995446 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:38:08,781] Trial 33 finished with value: 0.7624486790737437 and parameters: {'n_estimators': 50, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:40:18,401] Trial 34 finished with value: 0.8500171510457282 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:41:09,813] Trial 35 finished with value: 0.8309425107426811 and parameters: {'n_estimators': 200, 'learning_rate': 0.3, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:43:03,803] Trial 36 finished with value: 0.8488892939651921 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:44:21,671] Trial 37 finished with value: 0.8174932908425138 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:44:29,252] Trial 38 finished with value: 0.48322283789007214 and parameters: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:44:39,267] Trial 39 finished with value: 0.769525873565582 and parameters: {'n_estimators': 50, 'learning_rate': 0.3, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:44:56,731] Trial 40 finished with value: 0.615982137786647 and parameters: {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.6, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:47:07,147] Trial 41 finished with value: 0.8493884420995446 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 27 with value: 0.8538789662783184.\n",
      "[I 2023-07-24 14:49:23,949] Trial 42 finished with value: 0.8546626431600206 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 14:50:48,201] Trial 43 finished with value: 0.8484257357298723 and parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 14:53:23,788] Trial 44 finished with value: 0.8252737746345847 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 14:55:37,724] Trial 45 finished with value: 0.8482691318907148 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.7, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 14:57:24,443] Trial 46 finished with value: 0.8541561622059157 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 14:58:00,327] Trial 47 finished with value: 0.7514396030056487 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 14:58:45,754] Trial 48 finished with value: 0.733090161663543 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 14:58:58,684] Trial 49 finished with value: 0.8198830561663859 and parameters: {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 14:59:14,088] Trial 50 finished with value: 0.6440326677718625 and parameters: {'n_estimators': 200, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:01:27,040] Trial 51 finished with value: 0.8516811026228399 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:03:04,746] Trial 52 finished with value: 0.8509172683443778 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:04:27,763] Trial 53 finished with value: 0.6852875346401277 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:05:44,240] Trial 54 finished with value: 0.8115055723147503 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 15:07:38,220] Trial 55 finished with value: 0.8337101317959563 and parameters: {'n_estimators': 500, 'learning_rate': 0.3, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:09:18,316] Trial 56 finished with value: 0.8335315642506271 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:11:15,563] Trial 57 finished with value: 0.8462308380078047 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:13:03,680] Trial 58 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:13:34,770] Trial 59 finished with value: 0.7521484207681105 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:14:03,597] Trial 60 finished with value: 0.8324350053739739 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:16:07,496] Trial 61 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:18:06,211] Trial 62 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:20:04,986] Trial 63 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:22:03,270] Trial 64 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:23:56,478] Trial 65 finished with value: 0.8487376951463605 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:25:09,962] Trial 66 finished with value: 0.8304550595097913 and parameters: {'n_estimators': 400, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:25:49,004] Trial 67 finished with value: 0.6683814343701471 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:27:47,822] Trial 68 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:28:36,616] Trial 69 finished with value: 0.7303644975236647 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:28:44,212] Trial 70 finished with value: 0.7286422078074709 and parameters: {'n_estimators': 50, 'learning_rate': 0.25, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:30:44,153] Trial 71 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:32:46,902] Trial 72 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:34:41,307] Trial 73 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:36:52,808] Trial 74 finished with value: 0.8545475745978184 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:38:15,400] Trial 75 finished with value: 0.8247514782658465 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:39:05,394] Trial 76 finished with value: 0.8486794893310066 and parameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:41:25,821] Trial 77 finished with value: 0.8265215799783622 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:41:51,890] Trial 78 finished with value: 0.8328261004030558 and parameters: {'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:42:54,238] Trial 79 finished with value: 0.7467538717644597 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:44:18,517] Trial 80 finished with value: 0.8447510940821239 and parameters: {'n_estimators': 400, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.7, 'colsample_bytree': 0.6, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:46:20,016] Trial 81 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:48:23,099] Trial 82 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:50:23,813] Trial 83 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 15:52:24,759] Trial 84 finished with value: 0.8330489773002684 and parameters: {'n_estimators': 500, 'learning_rate': 0.25, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:54:14,915] Trial 85 finished with value: 0.8509507379618716 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:55:12,451] Trial 86 finished with value: 0.8437053686665875 and parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.6, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:57:00,441] Trial 87 finished with value: 0.8412625926883699 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:57:34,194] Trial 88 finished with value: 0.6667676634101838 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.8, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:58:13,167] Trial 89 finished with value: 0.6913973549419753 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.8, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 15:58:26,906] Trial 90 finished with value: 0.8175288525969631 and parameters: {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 16:00:09,906] Trial 91 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 16:01:52,613] Trial 92 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 16:04:04,146] Trial 93 finished with value: 0.8531378897066478 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 16:05:39,540] Trial 94 finished with value: 0.8398956593232973 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 16:07:42,066] Trial 95 finished with value: 0.8527311553597725 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6, 'colsample_bytree': 0.7, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 16:08:17,268] Trial 96 finished with value: 0.5672482825770973 and parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'random_state': 42}. Best is trial 42 with value: 0.8546626431600206.\n",
      "[I 2023-07-24 16:10:16,466] Trial 97 finished with value: 0.8550232250139043 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 97 with value: 0.8550232250139043.\n",
      "[I 2023-07-24 16:12:21,415] Trial 98 finished with value: 0.8535739769107641 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 97 with value: 0.8550232250139043.\n",
      "[I 2023-07-24 16:12:49,763] Trial 99 finished with value: 0.8251937971633498 and parameters: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.8, 'random_state': 42}. Best is trial 97 with value: 0.8550232250139043.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import optuna\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# train.csv 파일 불러오기\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# 결측치를 평균값으로 대체\n",
    "train_data = train_data.fillna(train_data.mean())\n",
    "\n",
    "# '측정 시간대'를 원핫 인코딩하여 숫자 형태로 변환\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "time_encoded = encoder.fit_transform(train_data[['측정 시간대']])\n",
    "time_encoded_df = pd.DataFrame(time_encoded, columns=encoder.get_feature_names(['측정 시간대']))\n",
    "train_data = pd.concat([train_data, time_encoded_df], axis=1).drop(['측정 시간대'], axis=1)\n",
    "\n",
    "# 풍속을 예측할 특성(입력 변수)과 풍속(출력 변수)을 분리합니다.\n",
    "X_train = train_data.drop(['ID', '풍속 (m/s)'], axis=1)  # 입력 변수들\n",
    "y_train = train_data['풍속 (m/s)']  # 출력 변수 (풍속)\n",
    "\n",
    "# ARIMA 모델 생성과 예측\n",
    "def arima_forecast(train_data, test_data):\n",
    "    train_data.set_index('일시', inplace=True)\n",
    "    test_data.set_index('일시', inplace=True)\n",
    "\n",
    "    # ARIMA 모델 생성\n",
    "    model = ARIMA(train_data['풍속 (m/s)'], order=(1, 1, 1))\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # 테스트 데이터로 예측 수행\n",
    "    forecast = model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "    # 예측 결과만 추출하여 반환\n",
    "    return forecast[0]\n",
    "\n",
    "\n",
    "# 최적의 하이퍼파라미터 탐색 함수\n",
    "def optimize_hyperparameters(X, y, model, params):\n",
    "    def objective(trial):\n",
    "        # trial.suggest_categorical 함수의 리턴값을 임시 변수에 저장하여 사용\n",
    "        suggested_params = {}\n",
    "        for param_name, param_range in params.items():\n",
    "            suggested_params[param_name] = trial.suggest_categorical(param_name, param_range)\n",
    "        model.set_params(**suggested_params)\n",
    "\n",
    "        cv_scores = cross_val_score(model, X, y, cv=5, n_jobs=-1)\n",
    "        return np.mean(cv_scores)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "# 부스팅 모델 생성\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "lgb_model = LGBMRegressor(random_state=42)\n",
    "cat_model = CatBoostRegressor(random_state=42)\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# 모델 학습 (Linear Regression, SVR)\n",
    "lr_model = LinearRegression()\n",
    "svr_model = SVR()\n",
    "\n",
    "# 하이퍼파라미터 탐색 범위\n",
    "xgb_params = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_child_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "    'random_state': [42],\n",
    "}\n",
    "\n",
    "lgb_params = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'num_leaves': [10, 20, 30, 40, 50, 100, 200],\n",
    "    'feature_fraction': [0.6, 0.7, 0.8, 0.9],\n",
    "    'bagging_fraction': [0.6, 0.7, 0.8, 0.9],\n",
    "    'random_state': [42],\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': [50, 100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    'depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'random_strength': [0.01, 0.1, 1, 10],\n",
    "    'bagging_temperature': [0.01, 0.1, 1, 10, 100],\n",
    "    'random_state': [42],\n",
    "}\n",
    "\n",
    "# XGBoost 모델의 최적 하이퍼파라미터 탐색\n",
    "xgb_best_params = optimize_hyperparameters(X_train, y_train, xgb_model, xgb_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ea8a249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"\n",
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# train.csv 파일 불러오기\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# 결측치를 평균값으로 대체\n",
    "train_data = train_data.fillna(train_data.mean())\n",
    "\n",
    "# '측정 시간대'를 원핫 인코딩하여 숫자 형태로 변환\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "time_encoded = encoder.fit_transform(train_data[['측정 시간대']])\n",
    "time_encoded_df = pd.DataFrame(time_encoded, columns=encoder.get_feature_names(['측정 시간대']))\n",
    "train_data = pd.concat([train_data, time_encoded_df], axis=1).drop(['측정 시간대'], axis=1)\n",
    "\n",
    "# 풍속을 예측할 특성(입력 변수)과 풍속(출력 변수)을 분리합니다.\n",
    "X_train = train_data.drop(['ID', '풍속 (m/s)'], axis=1)  # 입력 변수들\n",
    "y_train = train_data['풍속 (m/s)']  # 출력 변수 (풍속)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fbbff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 16:12:49,813] A new study created in memory with name: no-name-847b6b9c-5f23-464b-b2ac-ed9b8014f6cf\n",
      "[I 2023-07-24 16:12:52,214] Trial 0 finished with value: 0.603455417181317 and parameters: {'n_estimators': 50, 'learning_rate': 0.25, 'max_depth': 4, 'num_leaves': 10, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 0 with value: 0.603455417181317.\n",
      "[I 2023-07-24 16:12:54,178] Trial 1 finished with value: 0.1728181340355746 and parameters: {'n_estimators': 50, 'learning_rate': 0.01, 'max_depth': 3, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 0 with value: 0.603455417181317.\n",
      "[I 2023-07-24 16:12:55,108] Trial 2 finished with value: 0.4904244767814677 and parameters: {'n_estimators': 50, 'learning_rate': 0.05, 'max_depth': 4, 'num_leaves': 40, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 0 with value: 0.603455417181317.\n",
      "[I 2023-07-24 16:13:08,903] Trial 3 finished with value: 0.8418071650480684 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 9, 'num_leaves': 200, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:13:10,484] Trial 4 finished with value: 0.33348890689545607 and parameters: {'n_estimators': 100, 'learning_rate': 0.01, 'max_depth': 4, 'num_leaves': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:13:14,540] Trial 5 finished with value: 0.7637602960397741 and parameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 6, 'num_leaves': 40, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:13:16,715] Trial 6 finished with value: 0.7490909500447811 and parameters: {'n_estimators': 200, 'learning_rate': 0.15, 'max_depth': 6, 'num_leaves': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:13:22,113] Trial 7 finished with value: 0.8235126462461462 and parameters: {'n_estimators': 300, 'learning_rate': 0.2, 'max_depth': 8, 'num_leaves': 40, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:13:24,670] Trial 8 finished with value: 0.6587749995849751 and parameters: {'n_estimators': 300, 'learning_rate': 0.15, 'max_depth': 3, 'num_leaves': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:13:26,255] Trial 9 finished with value: 0.7348755692446302 and parameters: {'n_estimators': 100, 'learning_rate': 0.2, 'max_depth': 7, 'num_leaves': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:13:40,054] Trial 10 finished with value: 0.8418071650480684 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 9, 'num_leaves': 200, 'feature_fraction': 0.8, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:13:54,999] Trial 11 finished with value: 0.8418071650480684 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 9, 'num_leaves': 200, 'feature_fraction': 0.8, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:14:08,883] Trial 12 finished with value: 0.837761958378645 and parameters: {'n_estimators': 400, 'learning_rate': 0.3, 'max_depth': 9, 'num_leaves': 200, 'feature_fraction': 0.8, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:14:14,488] Trial 13 finished with value: 0.8289250132810982 and parameters: {'n_estimators': 400, 'learning_rate': 0.25, 'max_depth': 9, 'num_leaves': 30, 'feature_fraction': 0.8, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 3 with value: 0.8418071650480684.\n",
      "[I 2023-07-24 16:14:30,637] Trial 14 finished with value: 0.8461757351978108 and parameters: {'n_estimators': 500, 'learning_rate': 0.25, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 14 with value: 0.8461757351978108.\n",
      "[I 2023-07-24 16:14:46,382] Trial 15 finished with value: 0.8461757351978108 and parameters: {'n_estimators': 500, 'learning_rate': 0.25, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'random_state': 42}. Best is trial 14 with value: 0.8461757351978108.\n",
      "[I 2023-07-24 16:15:04,455] Trial 16 finished with value: 0.8346719419784794 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 14 with value: 0.8461757351978108.\n",
      "[I 2023-07-24 16:15:20,586] Trial 17 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:15:35,799] Trial 18 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:15:43,590] Trial 19 finished with value: 0.785038496270645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 5, 'num_leaves': 50, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:16:00,049] Trial 20 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:16:17,587] Trial 21 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:16:34,207] Trial 22 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:16:50,518] Trial 23 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:17:07,752] Trial 24 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:17:15,427] Trial 25 finished with value: 0.785038496270645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 5, 'num_leaves': 50, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:17:22,223] Trial 26 finished with value: 0.8312761020691022 and parameters: {'n_estimators': 500, 'learning_rate': 0.3, 'max_depth': 8, 'num_leaves': 30, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:17:26,744] Trial 27 finished with value: 0.7452808981970304 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 7, 'num_leaves': 10, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 16:17:30,592] Trial 28 finished with value: 0.8029478263134251 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:17:33,242] Trial 29 finished with value: 0.7081127236765157 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 10, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:17:40,396] Trial 30 finished with value: 0.8271132373697332 and parameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:17:58,554] Trial 31 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:18:01,075] Trial 32 finished with value: 0.36711770299455015 and parameters: {'n_estimators': 50, 'learning_rate': 0.01, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:18:05,551] Trial 33 finished with value: 0.673927989688913 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 3, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:18:06,545] Trial 34 finished with value: 0.4904244767814677 and parameters: {'n_estimators': 50, 'learning_rate': 0.05, 'max_depth': 4, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:18:22,802] Trial 35 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:18:35,057] Trial 36 finished with value: 0.721673767245403 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 10, 'num_leaves': 50, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:18:38,660] Trial 37 finished with value: 0.734957359107867 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 4, 'num_leaves': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:18:41,981] Trial 38 finished with value: 0.8078005334735534 and parameters: {'n_estimators': 200, 'learning_rate': 0.3, 'max_depth': 6, 'num_leaves': 40, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:18:43,651] Trial 39 finished with value: 0.7562709447146978 and parameters: {'n_estimators': 100, 'learning_rate': 0.2, 'max_depth': 8, 'num_leaves': 30, 'feature_fraction': 0.6, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:18:45,456] Trial 40 finished with value: 0.7241488307165979 and parameters: {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 7, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:19:01,388] Trial 41 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:19:16,942] Trial 42 finished with value: 0.8471537199070645 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:19:20,940] Trial 43 finished with value: 0.673927989688913 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 3, 'num_leaves': 100, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:19:25,154] Trial 44 finished with value: 0.7704329953352642 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'num_leaves': 20, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:19:32,994] Trial 45 finished with value: 0.8199829007215618 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 6, 'num_leaves': 40, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:19:46,425] Trial 46 finished with value: 0.8342337667472293 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 10, 'num_leaves': 100, 'feature_fraction': 0.6, 'bagging_fraction': 0.7, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:19:49,211] Trial 47 finished with value: 0.7299891037311713 and parameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5, 'num_leaves': 100, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'random_state': 42}. Best is trial 17 with value: 0.8471537199070645.\n",
      "[I 2023-07-24 16:20:07,393] Trial 48 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:20:12,240] Trial 49 finished with value: 0.8314900818103801 and parameters: {'n_estimators': 100, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:20:16,463] Trial 50 finished with value: 0.7615719708830625 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 4, 'num_leaves': 200, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:20:33,038] Trial 51 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:20:50,679] Trial 52 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:21:08,330] Trial 53 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:21:24,911] Trial 54 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:21:38,267] Trial 55 finished with value: 0.8459589724649119 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 9, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:21:48,839] Trial 56 finished with value: 0.8460125943622044 and parameters: {'n_estimators': 300, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 16:21:58,301] Trial 57 finished with value: 0.8376439354627022 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 7, 'num_leaves': 200, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:22:10,356] Trial 58 finished with value: 0.8433819375988225 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 8, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:22:21,551] Trial 59 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:22:24,247] Trial 60 finished with value: 0.6942806635236402 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 3, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:22:37,865] Trial 61 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:22:51,305] Trial 62 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:23:05,259] Trial 63 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:23:18,524] Trial 64 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:23:31,484] Trial 65 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:23:36,313] Trial 66 finished with value: 0.7927398891175516 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 5, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:23:50,365] Trial 67 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:23:57,612] Trial 68 finished with value: 0.8180053056717135 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 6, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:24:00,475] Trial 69 finished with value: 0.8191115389463188 and parameters: {'n_estimators': 50, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.7, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:24:05,323] Trial 70 finished with value: 0.8263979166283812 and parameters: {'n_estimators': 100, 'learning_rate': 0.2, 'max_depth': 9, 'num_leaves': 200, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:24:17,820] Trial 71 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:24:29,971] Trial 72 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:24:43,638] Trial 73 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:24:56,922] Trial 74 finished with value: 0.8472361922852656 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:25:12,542] Trial 75 finished with value: 0.8458485324748299 and parameters: {'n_estimators': 500, 'learning_rate': 0.25, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.6, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:25:16,896] Trial 76 finished with value: 0.563888946607879 and parameters: {'n_estimators': 200, 'learning_rate': 0.01, 'max_depth': 10, 'num_leaves': 30, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:25:21,946] Trial 77 finished with value: 0.8217609336243991 and parameters: {'n_estimators': 500, 'learning_rate': 0.3, 'max_depth': 10, 'num_leaves': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:25:27,617] Trial 78 finished with value: 0.8306201145123888 and parameters: {'n_estimators': 300, 'learning_rate': 0.2, 'max_depth': 8, 'num_leaves': 50, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:25:41,592] Trial 79 finished with value: 0.8475450892299878 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:25:52,505] Trial 80 finished with value: 0.8374010460068803 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 7, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:26:07,330] Trial 81 finished with value: 0.8475450892299878 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:26:22,414] Trial 82 finished with value: 0.8475450892299878 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:26:38,126] Trial 83 finished with value: 0.8475450892299878 and parameters: {'n_estimators': 400, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:26:45,600] Trial 84 finished with value: 0.831420813025122 and parameters: {'n_estimators': 400, 'learning_rate': 0.15, 'max_depth': 10, 'num_leaves': 40, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:26:50,139] Trial 85 finished with value: 0.6698224064878506 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 4, 'num_leaves': 10, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 16:27:10,376] Trial 86 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:27:29,830] Trial 87 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:27:33,720] Trial 88 finished with value: 0.7140320892295486 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 3, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:27:39,001] Trial 89 finished with value: 0.82436894583506 and parameters: {'n_estimators': 500, 'learning_rate': 0.25, 'max_depth': 10, 'num_leaves': 20, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:27:47,973] Trial 90 finished with value: 0.6271945810103265 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 5, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:28:06,088] Trial 91 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:28:24,717] Trial 92 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:28:42,379] Trial 93 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:29:00,567] Trial 94 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:29:08,378] Trial 95 finished with value: 0.8240659850675367 and parameters: {'n_estimators': 500, 'learning_rate': 0.3, 'max_depth': 6, 'num_leaves': 30, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:29:18,008] Trial 96 finished with value: 0.8438629841355736 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 50, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:29:36,804] Trial 97 finished with value: 0.8482802833434364 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 10, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:29:52,795] Trial 98 finished with value: 0.8459589724649119 and parameters: {'n_estimators': 500, 'learning_rate': 0.2, 'max_depth': 9, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n",
      "[I 2023-07-24 16:29:57,468] Trial 99 finished with value: 0.7710143490825725 and parameters: {'n_estimators': 500, 'learning_rate': 0.15, 'max_depth': 10, 'num_leaves': 10, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'random_state': 42}. Best is trial 48 with value: 0.8482802833434364.\n"
     ]
    }
   ],
   "source": [
    "# LightGBM 모델의 최적 하이퍼파라미터 탐색\n",
    "lgb_best_params = optimize_hyperparameters(X_train, y_train, lgb_model, lgb_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a3abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 16:29:57,491] A new study created in memory with name: no-name-69ed59ab-4ea6-4bbe-8ecc-3ac0590a9fc4\n",
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "4 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\catboost\\core.py\", line 5737, in fit\n",
      "    save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\catboost\\core.py\", line 2362, in _fit\n",
      "    train_params[\"init_model\"]\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\catboost\\core.py\", line 1761, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4624, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4673, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "[W 2023-07-24 16:30:01,217] Trial 0 failed with parameters: {'iterations': 100, 'learning_rate': 0.2, 'depth': 4, 'random_strength': 0.1, 'bagging_temperature': 1, 'random_state': 42} because of the following error: The value nan is not acceptable..\n",
      "[W 2023-07-24 16:30:01,219] Trial 0 failed with value nan.\n",
      "[I 2023-07-24 16:30:28,943] Trial 1 finished with value: 0.6056454996367683 and parameters: {'iterations': 100, 'learning_rate': 0.05, 'depth': 10, 'random_strength': 10, 'bagging_temperature': 0.1, 'random_state': 42}. Best is trial 1 with value: 0.6056454996367683.\n",
      "[I 2023-07-24 16:30:30,909] Trial 2 finished with value: 0.5737479707830115 and parameters: {'iterations': 50, 'learning_rate': 0.25, 'depth': 4, 'random_strength': 1, 'bagging_temperature': 1, 'random_state': 42}. Best is trial 1 with value: 0.6056454996367683.\n",
      "[I 2023-07-24 16:30:49,633] Trial 3 finished with value: 0.7584951015927033 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 5, 'random_strength': 0.1, 'bagging_temperature': 1, 'random_state': 42}. Best is trial 3 with value: 0.7584951015927033.\n",
      "[I 2023-07-24 16:31:23,695] Trial 4 finished with value: 0.7578814943677814 and parameters: {'iterations': 400, 'learning_rate': 0.05, 'depth': 8, 'random_strength': 1, 'bagging_temperature': 1, 'random_state': 42}. Best is trial 3 with value: 0.7584951015927033.\n",
      "[I 2023-07-24 16:33:36,741] Trial 5 finished with value: 0.8143689827905677 and parameters: {'iterations': 500, 'learning_rate': 0.05, 'depth': 10, 'random_strength': 0.01, 'bagging_temperature': 0.1, 'random_state': 42}. Best is trial 5 with value: 0.8143689827905677.\n",
      "[I 2023-07-24 16:34:41,417] Trial 6 finished with value: 0.8393020374906548 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:34:46,074] Trial 7 finished with value: 0.6398206547461003 and parameters: {'iterations': 50, 'learning_rate': 0.3, 'depth': 7, 'random_strength': 10, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:35:03,547] Trial 8 finished with value: 0.7412238208173113 and parameters: {'iterations': 400, 'learning_rate': 0.1, 'depth': 6, 'random_strength': 10, 'bagging_temperature': 0.1, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:35:17,433] Trial 9 finished with value: 0.7734767596723775 and parameters: {'iterations': 100, 'learning_rate': 0.2, 'depth': 9, 'random_strength': 1, 'bagging_temperature': 0.1, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:35:19,339] Trial 10 finished with value: 0.4683044816936244 and parameters: {'iterations': 50, 'learning_rate': 0.15, 'depth': 3, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:35:58,941] Trial 11 finished with value: 0.6022235119687401 and parameters: {'iterations': 300, 'learning_rate': 0.01, 'depth': 9, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:37:55,420] Trial 12 finished with value: 0.8143689827905677 and parameters: {'iterations': 500, 'learning_rate': 0.05, 'depth': 10, 'random_strength': 0.01, 'bagging_temperature': 0.01, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:38:34,851] Trial 13 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:38:55,440] Trial 14 finished with value: 0.8045969365242452 and parameters: {'iterations': 200, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:39:44,871] Trial 15 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:40:34,073] Trial 16 finished with value: 0.8393020374906548 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:40:38,277] Trial 17 finished with value: 0.6486219958976706 and parameters: {'iterations': 200, 'learning_rate': 0.3, 'depth': 3, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:40:51,887] Trial 18 finished with value: 0.7639480433112672 and parameters: {'iterations': 300, 'learning_rate': 0.1, 'depth': 7, 'random_strength': 0.1, 'bagging_temperature': 0.01, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:41:08,664] Trial 19 finished with value: 0.8058973410938698 and parameters: {'iterations': 500, 'learning_rate': 0.25, 'depth': 6, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:41:40,158] Trial 20 finished with value: 0.8322397217168147 and parameters: {'iterations': 500, 'learning_rate': 0.2, 'depth': 8, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:41:55,322] Trial 21 finished with value: 0.5297876341194325 and parameters: {'iterations': 500, 'learning_rate': 0.01, 'depth': 5, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:42:51,980] Trial 22 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:43:47,064] Trial 23 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:44:38,762] Trial 24 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 16:44:52,218] Trial 25 finished with value: 0.7213281387270882 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 4, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:45:33,941] Trial 26 finished with value: 0.8222635222830297 and parameters: {'iterations': 300, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:46:35,011] Trial 27 finished with value: 0.8319409075161228 and parameters: {'iterations': 400, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 0.01, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:46:49,417] Trial 28 finished with value: 0.7093468345184508 and parameters: {'iterations': 100, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 10, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:47:16,819] Trial 29 finished with value: 0.5446518458871907 and parameters: {'iterations': 200, 'learning_rate': 0.01, 'depth': 9, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:47:20,272] Trial 30 finished with value: 0.4827582753303109 and parameters: {'iterations': 100, 'learning_rate': 0.1, 'depth': 4, 'random_strength': 10, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:48:03,509] Trial 31 finished with value: 0.8360161073673733 and parameters: {'iterations': 500, 'learning_rate': 0.25, 'depth': 8, 'random_strength': 0.01, 'bagging_temperature': 0.01, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:49:12,254] Trial 32 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:50:19,580] Trial 33 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:50:37,626] Trial 34 finished with value: 0.758462320465935 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 5, 'random_strength': 0.01, 'bagging_temperature': 1, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:51:46,829] Trial 35 finished with value: 0.8377084637769139 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 1, 'bagging_temperature': 1, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:52:01,916] Trial 36 finished with value: 0.7516134852363974 and parameters: {'iterations': 50, 'learning_rate': 0.2, 'depth': 10, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:52:14,480] Trial 37 finished with value: 0.7082691528204497 and parameters: {'iterations': 500, 'learning_rate': 0.3, 'depth': 3, 'random_strength': 0.1, 'bagging_temperature': 0.1, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:52:32,393] Trial 38 finished with value: 0.7025885512600806 and parameters: {'iterations': 400, 'learning_rate': 0.05, 'depth': 6, 'random_strength': 0.01, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:53:01,947] Trial 39 finished with value: 0.8203514002662897 and parameters: {'iterations': 500, 'learning_rate': 0.25, 'depth': 7, 'random_strength': 10, 'bagging_temperature': 1, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:53:09,673] Trial 40 finished with value: 0.6930526260161984 and parameters: {'iterations': 50, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:53:13,431] Trial 41 finished with value: 0.5980641156841191 and parameters: {'iterations': 100, 'learning_rate': 0.15, 'depth': 4, 'random_strength': 0.1, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:54:22,728] Trial 42 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:55:31,153] Trial 43 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:56:36,423] Trial 44 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:57:41,293] Trial 45 finished with value: 0.8385397835477487 and parameters: {'iterations': 500, 'learning_rate': 0.15, 'depth': 9, 'random_strength': 0.01, 'bagging_temperature': 0.1, 'random_state': 42}. Best is trial 6 with value: 0.8393020374906548.\n",
      "[I 2023-07-24 16:59:01,775] Trial 46 finished with value: 0.8437268573067364 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 0.01, 'bagging_temperature': 10, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:00:21,160] Trial 47 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:01:42,236] Trial 48 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:03:03,520] Trial 49 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:04:23,765] Trial 50 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:05:43,548] Trial 51 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:06:57,896] Trial 52 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:08:15,592] Trial 53 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:09:35,629] Trial 54 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:10:58,457] Trial 55 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 17:12:10,243] Trial 56 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:13:11,136] Trial 57 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:14:13,767] Trial 58 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:15:10,056] Trial 59 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:16:05,963] Trial 60 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:17:01,571] Trial 61 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:17:57,470] Trial 62 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:18:53,691] Trial 63 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:19:49,866] Trial 64 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:20:46,377] Trial 65 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:21:42,173] Trial 66 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:22:41,505] Trial 67 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:23:01,687] Trial 68 finished with value: 0.783619122070607 and parameters: {'iterations': 300, 'learning_rate': 0.1, 'depth': 8, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:23:52,508] Trial 69 finished with value: 0.7484226702918805 and parameters: {'iterations': 200, 'learning_rate': 0.05, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:24:02,734] Trial 70 finished with value: 0.7628764503798531 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 5, 'random_strength': 1, 'bagging_temperature': 0.01, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:24:19,183] Trial 71 finished with value: 0.7953392741947516 and parameters: {'iterations': 300, 'learning_rate': 0.2, 'depth': 7, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:25:28,914] Trial 72 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:26:38,552] Trial 73 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:28:17,517] Trial 74 finished with value: 0.6227301112006822 and parameters: {'iterations': 300, 'learning_rate': 0.01, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:28:37,293] Trial 75 finished with value: 0.7984919192505738 and parameters: {'iterations': 400, 'learning_rate': 0.3, 'depth': 6, 'random_strength': 10, 'bagging_temperature': 0.1, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:28:46,691] Trial 76 finished with value: 0.6762109889321285 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 3, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:30:17,191] Trial 77 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:30:35,920] Trial 78 finished with value: 0.7668984031102724 and parameters: {'iterations': 50, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 1, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:32:04,300] Trial 79 finished with value: 0.8421010649665099 and parameters: {'iterations': 300, 'learning_rate': 0.25, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:32:59,038] Trial 80 finished with value: 0.8330289500870973 and parameters: {'iterations': 200, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:33:08,854] Trial 81 finished with value: 0.6371715080861959 and parameters: {'iterations': 300, 'learning_rate': 0.1, 'depth': 4, 'random_strength': 10, 'bagging_temperature': 0.01, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:34:31,824] Trial 82 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:36:01,519] Trial 83 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:36:29,482] Trial 84 finished with value: 0.8082617507106754 and parameters: {'iterations': 100, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:37:52,769] Trial 85 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:38:04,516] Trial 86 finished with value: 0.46062460956069023 and parameters: {'iterations': 300, 'learning_rate': 0.01, 'depth': 5, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-24 17:38:30,984] Trial 87 finished with value: 0.7341067557984502 and parameters: {'iterations': 300, 'learning_rate': 0.05, 'depth': 8, 'random_strength': 1, 'bagging_temperature': 0.1, 'random_state': 42}. Best is trial 46 with value: 0.8437268573067364.\n",
      "[I 2023-07-24 17:40:21,954] Trial 88 finished with value: 0.8475583263119593 and parameters: {'iterations': 400, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:40:47,901] Trial 89 finished with value: 0.8085951738449145 and parameters: {'iterations': 400, 'learning_rate': 0.2, 'depth': 7, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:40:58,933] Trial 90 finished with value: 0.69482147074628 and parameters: {'iterations': 400, 'learning_rate': 0.3, 'depth': 3, 'random_strength': 1, 'bagging_temperature': 1, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:41:15,932] Trial 91 finished with value: 0.8021181771959653 and parameters: {'iterations': 400, 'learning_rate': 0.3, 'depth': 6, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:42:40,305] Trial 92 finished with value: 0.8424065085370337 and parameters: {'iterations': 300, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:44:32,286] Trial 93 finished with value: 0.8475583263119593 and parameters: {'iterations': 400, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:46:23,647] Trial 94 finished with value: 0.8475583263119593 and parameters: {'iterations': 400, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:48:15,474] Trial 95 finished with value: 0.8475583263119593 and parameters: {'iterations': 400, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:50:05,055] Trial 96 finished with value: 0.8475583263119593 and parameters: {'iterations': 400, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 1, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:51:11,839] Trial 97 finished with value: 0.8473666901005572 and parameters: {'iterations': 400, 'learning_rate': 0.3, 'depth': 10, 'random_strength': 10, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:52:07,192] Trial 98 finished with value: 0.847305471323654 and parameters: {'iterations': 400, 'learning_rate': 0.25, 'depth': 10, 'random_strength': 10, 'bagging_temperature': 100, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n",
      "[I 2023-07-24 17:53:00,023] Trial 99 finished with value: 0.847305471323654 and parameters: {'iterations': 400, 'learning_rate': 0.25, 'depth': 10, 'random_strength': 10, 'bagging_temperature': 0.01, 'random_state': 42}. Best is trial 88 with value: 0.8475583263119593.\n"
     ]
    }
   ],
   "source": [
    "# CatBoost 모델의 최적 하이퍼파라미터 탐색\n",
    "cat_best_params = optimize_hyperparameters(X_train, y_train, cat_model, cat_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45bdc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼파라미터로 모델 생성\n",
    "xgb_model = XGBRegressor(**xgb_best_params)\n",
    "lgb_model = LGBMRegressor(**lgb_best_params)\n",
    "cat_model = CatBoostRegressor(**cat_best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39fbbb91",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The DType <class 'numpy.dtype[datetime64]'> could not be promoted by <class 'numpy.dtype[float64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 289, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 289, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 42, in _fit_single_estimator\n    estimator.fit(X, y)\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 328, in fit\n    X, y, multi_output=True, accept_sparse=\"csc\", dtype=DTYPE\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 976, in check_X_y\n    estimator=estimator,\n  File \"C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 665, in check_array\n    dtype_orig = np.result_type(*dtypes_orig)\n  File \"<__array_function__ internals>\", line 6, in result_type\nTypeError: The DType <class 'numpy.dtype[datetime64]'> could not be promoted by <class 'numpy.dtype[float64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15152\\2870476183.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# 앙상블 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mensemble_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# 스태킹 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \"\"\"\n\u001b[0;32m    528\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             )\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"drop\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    566\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The DType <class 'numpy.dtype[datetime64]'> could not be promoted by <class 'numpy.dtype[float64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>)"
     ]
    }
   ],
   "source": [
    "# 앙상블 모델 생성\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('rf', rf_model),\n",
    "    ('xgb', xgb_model),\n",
    "    ('lgb', lgb_model),\n",
    "    ('cat', cat_model),\n",
    "    ('gb', gb_model)\n",
    "], n_jobs=-1)\n",
    "\n",
    "# 스태킹을 위한 모델 생성\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgb', lgb_model),\n",
    "        ('cat', cat_model),\n",
    "        ('gb', gb_model)\n",
    "    ],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# 스태킹 모델 학습\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# test.csv 파일 불러오기\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# 결측치를 평균값으로 대체\n",
    "test_data = test_data.fillna(test_data.mean())\n",
    "\n",
    "# '측정 시간대'를 원핫 인코딩하여 숫자 형태로 변환\n",
    "time_encoded = encoder.transform(test_data[['측정 시간대']])\n",
    "time_encoded_df = pd.DataFrame(time_encoded, columns=encoder.get_feature_names(['측정 시간대']))\n",
    "test_data = pd.concat([test_data, time_encoded_df], axis=1).drop(['측정 시간대'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4858901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"\n",
      "C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# test.csv 파일 불러오기\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# 결측치를 평균값으로 대체\n",
    "test_data = test_data.fillna(test_data.mean())\n",
    "\n",
    "# '측정 시간대'를 원핫 인코딩하여 숫자 형태로 변환\n",
    "time_encoded = encoder.transform(test_data[['측정 시간대']])\n",
    "time_encoded_df = pd.DataFrame(time_encoded, columns=encoder.get_feature_names(['측정 시간대']))\n",
    "test_data = pd.concat([test_data, time_encoded_df], axis=1).drop(['측정 시간대'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "730fcaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>월</th>\n",
       "      <th>일</th>\n",
       "      <th>섭씨 온도(°⁣C)</th>\n",
       "      <th>절대 온도(K)</th>\n",
       "      <th>이슬점 온도(°C)</th>\n",
       "      <th>상대 습도 (%)</th>\n",
       "      <th>대기압(mbar)</th>\n",
       "      <th>포화 증기압(mbar)</th>\n",
       "      <th>실제 증기압(mbar)</th>\n",
       "      <th>증기압 부족량(mbar)</th>\n",
       "      <th>수증기 함량 (g/kg)</th>\n",
       "      <th>공기 밀도 (g/m**3)</th>\n",
       "      <th>풍향 (deg)</th>\n",
       "      <th>일시</th>\n",
       "      <th>측정 시간대_새벽</th>\n",
       "      <th>측정 시간대_오전</th>\n",
       "      <th>측정 시간대_오후</th>\n",
       "      <th>측정 시간대_저녁</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>4.28</td>\n",
       "      <td>278.68</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>72.5</td>\n",
       "      <td>984.48</td>\n",
       "      <td>8.30</td>\n",
       "      <td>6.02</td>\n",
       "      <td>2.28</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1233.29</td>\n",
       "      <td>251.80</td>\n",
       "      <td>2024-03-24 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>13.40</td>\n",
       "      <td>286.81</td>\n",
       "      <td>10.36</td>\n",
       "      <td>81.8</td>\n",
       "      <td>996.98</td>\n",
       "      <td>15.40</td>\n",
       "      <td>12.59</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.89</td>\n",
       "      <td>1206.20</td>\n",
       "      <td>225.60</td>\n",
       "      <td>2024-09-24 18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>19.89</td>\n",
       "      <td>294.33</td>\n",
       "      <td>14.95</td>\n",
       "      <td>73.2</td>\n",
       "      <td>984.83</td>\n",
       "      <td>23.26</td>\n",
       "      <td>17.03</td>\n",
       "      <td>6.23</td>\n",
       "      <td>10.82</td>\n",
       "      <td>1163.06</td>\n",
       "      <td>10.39</td>\n",
       "      <td>2024-05-28 18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>-2.88</td>\n",
       "      <td>270.44</td>\n",
       "      <td>-4.47</td>\n",
       "      <td>88.7</td>\n",
       "      <td>998.02</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1284.19</td>\n",
       "      <td>260.20</td>\n",
       "      <td>2024-01-17 18:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>6.97</td>\n",
       "      <td>281.18</td>\n",
       "      <td>4.36</td>\n",
       "      <td>83.4</td>\n",
       "      <td>987.00</td>\n",
       "      <td>10.01</td>\n",
       "      <td>8.35</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.28</td>\n",
       "      <td>1223.47</td>\n",
       "      <td>262.50</td>\n",
       "      <td>2024-10-22 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15673</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1.61</td>\n",
       "      <td>274.67</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>85.9</td>\n",
       "      <td>1001.26</td>\n",
       "      <td>6.86</td>\n",
       "      <td>5.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1266.62</td>\n",
       "      <td>56.18</td>\n",
       "      <td>2024-03-16 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15674</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>18.27</td>\n",
       "      <td>292.19</td>\n",
       "      <td>13.35</td>\n",
       "      <td>73.0</td>\n",
       "      <td>990.98</td>\n",
       "      <td>21.03</td>\n",
       "      <td>15.35</td>\n",
       "      <td>5.68</td>\n",
       "      <td>9.69</td>\n",
       "      <td>1177.63</td>\n",
       "      <td>265.30</td>\n",
       "      <td>2024-09-05 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15675</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16.08</td>\n",
       "      <td>289.66</td>\n",
       "      <td>12.25</td>\n",
       "      <td>78.0</td>\n",
       "      <td>994.97</td>\n",
       "      <td>18.30</td>\n",
       "      <td>14.28</td>\n",
       "      <td>4.03</td>\n",
       "      <td>8.97</td>\n",
       "      <td>1191.84</td>\n",
       "      <td>189.80</td>\n",
       "      <td>2024-08-08 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15676</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.07</td>\n",
       "      <td>276.68</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>74.8</td>\n",
       "      <td>994.31</td>\n",
       "      <td>7.62</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1251.24</td>\n",
       "      <td>269.70</td>\n",
       "      <td>2024-02-04 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15677</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.01</td>\n",
       "      <td>283.38</td>\n",
       "      <td>8.36</td>\n",
       "      <td>95.7</td>\n",
       "      <td>985.13</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.01</td>\n",
       "      <td>0.49</td>\n",
       "      <td>6.98</td>\n",
       "      <td>1211.08</td>\n",
       "      <td>196.20</td>\n",
       "      <td>2024-02-01 06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15678 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        월   일  섭씨 온도(°⁣C)  절대 온도(K)  이슬점 온도(°C)  상대 습도 (%)  대기압(mbar)  \\\n",
       "0       3  24        4.28    278.68       -0.21       72.5     984.48   \n",
       "1       9  24       13.40    286.81       10.36       81.8     996.98   \n",
       "2       5  28       19.89    294.33       14.95       73.2     984.83   \n",
       "3       1  17       -2.88    270.44       -4.47       88.7     998.02   \n",
       "4      10  22        6.97    281.18        4.36       83.4     987.00   \n",
       "...    ..  ..         ...       ...         ...        ...        ...   \n",
       "15673   3  16        1.61    274.67       -0.49       85.9    1001.26   \n",
       "15674   9   5       18.27    292.19       13.35       73.0     990.98   \n",
       "15675   8   8       16.08    289.66       12.25       78.0     994.97   \n",
       "15676   2   4        3.07    276.68       -0.95       74.8     994.31   \n",
       "15677   2   1        9.01    283.38        8.36       95.7     985.13   \n",
       "\n",
       "       포화 증기압(mbar)  실제 증기압(mbar)  증기압 부족량(mbar)  수증기 함량 (g/kg)  \\\n",
       "0              8.30          6.02           2.28           3.81   \n",
       "1             15.40         12.59           2.80           7.89   \n",
       "2             23.26         17.03           6.23          10.82   \n",
       "3              4.94          4.38           0.56           2.73   \n",
       "4             10.01          8.35           1.66           5.28   \n",
       "...             ...           ...            ...            ...   \n",
       "15673          6.86          5.89           0.97           3.67   \n",
       "15674         21.03         15.35           5.68           9.69   \n",
       "15675         18.30         14.28           4.03           8.97   \n",
       "15676          7.62          5.70           1.92           3.57   \n",
       "15677         11.50         11.01           0.49           6.98   \n",
       "\n",
       "       공기 밀도 (g/m**3)  풍향 (deg)                  일시  측정 시간대_새벽  측정 시간대_오전  \\\n",
       "0             1233.29    251.80 2024-03-24 00:00:00        1.0        0.0   \n",
       "1             1206.20    225.60 2024-09-24 18:00:00        0.0        0.0   \n",
       "2             1163.06     10.39 2024-05-28 18:00:00        0.0        0.0   \n",
       "3             1284.19    260.20 2024-01-17 18:00:00        0.0        0.0   \n",
       "4             1223.47    262.50 2024-10-22 12:00:00        0.0        0.0   \n",
       "...               ...       ...                 ...        ...        ...   \n",
       "15673         1266.62     56.18 2024-03-16 00:00:00        1.0        0.0   \n",
       "15674         1177.63    265.30 2024-09-05 12:00:00        0.0        0.0   \n",
       "15675         1191.84    189.80 2024-08-08 00:00:00        1.0        0.0   \n",
       "15676         1251.24    269.70 2024-02-04 00:00:00        1.0        0.0   \n",
       "15677         1211.08    196.20 2024-02-01 06:00:00        0.0        1.0   \n",
       "\n",
       "       측정 시간대_오후  측정 시간대_저녁  \n",
       "0            0.0        0.0  \n",
       "1            0.0        1.0  \n",
       "2            0.0        1.0  \n",
       "3            0.0        1.0  \n",
       "4            1.0        0.0  \n",
       "...          ...        ...  \n",
       "15673        0.0        0.0  \n",
       "15674        1.0        0.0  \n",
       "15675        0.0        0.0  \n",
       "15676        0.0        0.0  \n",
       "15677        0.0        0.0  \n",
       "\n",
       "[15678 rows x 18 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터로 예측을 수행합니다.\n",
    "X_test = test_data.drop('ID', axis=1)  # 테스트 입력 변수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88005c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:49:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2858\n",
      "[LightGBM] [Info] Number of data points in the train set: 36581, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 2.036446\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0:\tlearn: 1.3579635\ttotal: 48.5ms\tremaining: 19.4s\n",
      "1:\tlearn: 1.2342349\ttotal: 97.7ms\tremaining: 19.4s\n",
      "2:\tlearn: 1.1633435\ttotal: 146ms\tremaining: 19.4s\n",
      "3:\tlearn: 1.1034396\ttotal: 191ms\tremaining: 18.9s\n",
      "4:\tlearn: 1.0603597\ttotal: 238ms\tremaining: 18.8s\n",
      "5:\tlearn: 1.0242043\ttotal: 282ms\tremaining: 18.5s\n",
      "6:\tlearn: 0.9935376\ttotal: 333ms\tremaining: 18.7s\n",
      "7:\tlearn: 0.9680994\ttotal: 382ms\tremaining: 18.7s\n",
      "8:\tlearn: 0.9477325\ttotal: 434ms\tremaining: 18.9s\n",
      "9:\tlearn: 0.9295203\ttotal: 486ms\tremaining: 18.9s\n",
      "10:\tlearn: 0.9169004\ttotal: 529ms\tremaining: 18.7s\n",
      "11:\tlearn: 0.9021130\ttotal: 580ms\tremaining: 18.8s\n",
      "12:\tlearn: 0.8823245\ttotal: 632ms\tremaining: 18.8s\n",
      "13:\tlearn: 0.8716624\ttotal: 683ms\tremaining: 18.8s\n",
      "14:\tlearn: 0.8648449\ttotal: 730ms\tremaining: 18.7s\n",
      "15:\tlearn: 0.8543324\ttotal: 780ms\tremaining: 18.7s\n",
      "16:\tlearn: 0.8463541\ttotal: 829ms\tremaining: 18.7s\n",
      "17:\tlearn: 0.8396610\ttotal: 880ms\tremaining: 18.7s\n",
      "18:\tlearn: 0.8350903\ttotal: 933ms\tremaining: 18.7s\n",
      "19:\tlearn: 0.8257762\ttotal: 997ms\tremaining: 18.9s\n",
      "20:\tlearn: 0.8149773\ttotal: 1.05s\tremaining: 18.9s\n",
      "21:\tlearn: 0.8099513\ttotal: 1.1s\tremaining: 19s\n",
      "22:\tlearn: 0.8016898\ttotal: 1.17s\tremaining: 19.1s\n",
      "23:\tlearn: 0.7958957\ttotal: 1.22s\tremaining: 19.1s\n",
      "24:\tlearn: 0.7903152\ttotal: 1.27s\tremaining: 19.1s\n",
      "25:\tlearn: 0.7831181\ttotal: 1.32s\tremaining: 19s\n",
      "26:\tlearn: 0.7781586\ttotal: 1.38s\tremaining: 19s\n",
      "27:\tlearn: 0.7729110\ttotal: 1.43s\tremaining: 18.9s\n",
      "28:\tlearn: 0.7646380\ttotal: 1.49s\tremaining: 19s\n",
      "29:\tlearn: 0.7598231\ttotal: 1.55s\tremaining: 19.1s\n",
      "30:\tlearn: 0.7549327\ttotal: 1.6s\tremaining: 19.1s\n",
      "31:\tlearn: 0.7512119\ttotal: 1.66s\tremaining: 19.1s\n",
      "32:\tlearn: 0.7463400\ttotal: 1.72s\tremaining: 19.1s\n",
      "33:\tlearn: 0.7415840\ttotal: 1.77s\tremaining: 19s\n",
      "34:\tlearn: 0.7376727\ttotal: 1.82s\tremaining: 19s\n",
      "35:\tlearn: 0.7349155\ttotal: 1.87s\tremaining: 18.9s\n",
      "36:\tlearn: 0.7303973\ttotal: 1.92s\tremaining: 18.8s\n",
      "37:\tlearn: 0.7238780\ttotal: 1.97s\tremaining: 18.7s\n",
      "38:\tlearn: 0.7185051\ttotal: 2.02s\tremaining: 18.7s\n",
      "39:\tlearn: 0.7135859\ttotal: 2.08s\tremaining: 18.7s\n",
      "40:\tlearn: 0.7102795\ttotal: 2.14s\tremaining: 18.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41:\tlearn: 0.7066704\ttotal: 2.19s\tremaining: 18.7s\n",
      "42:\tlearn: 0.7017103\ttotal: 2.26s\tremaining: 18.8s\n",
      "43:\tlearn: 0.6975606\ttotal: 2.32s\tremaining: 18.7s\n",
      "44:\tlearn: 0.6935913\ttotal: 2.37s\tremaining: 18.7s\n",
      "45:\tlearn: 0.6899025\ttotal: 2.43s\tremaining: 18.7s\n",
      "46:\tlearn: 0.6868145\ttotal: 2.49s\tremaining: 18.7s\n",
      "47:\tlearn: 0.6823574\ttotal: 2.55s\tremaining: 18.7s\n",
      "48:\tlearn: 0.6781622\ttotal: 2.6s\tremaining: 18.6s\n",
      "49:\tlearn: 0.6741693\ttotal: 2.66s\tremaining: 18.6s\n",
      "50:\tlearn: 0.6716267\ttotal: 2.72s\tremaining: 18.6s\n",
      "51:\tlearn: 0.6682115\ttotal: 2.78s\tremaining: 18.6s\n",
      "52:\tlearn: 0.6649706\ttotal: 2.84s\tremaining: 18.6s\n",
      "53:\tlearn: 0.6620427\ttotal: 2.9s\tremaining: 18.6s\n",
      "54:\tlearn: 0.6599763\ttotal: 2.96s\tremaining: 18.6s\n",
      "55:\tlearn: 0.6565916\ttotal: 3.01s\tremaining: 18.5s\n",
      "56:\tlearn: 0.6533533\ttotal: 3.07s\tremaining: 18.5s\n",
      "57:\tlearn: 0.6512974\ttotal: 3.12s\tremaining: 18.4s\n",
      "58:\tlearn: 0.6475936\ttotal: 3.18s\tremaining: 18.4s\n",
      "59:\tlearn: 0.6448109\ttotal: 3.24s\tremaining: 18.3s\n",
      "60:\tlearn: 0.6425553\ttotal: 3.29s\tremaining: 18.3s\n",
      "61:\tlearn: 0.6408529\ttotal: 3.35s\tremaining: 18.2s\n",
      "62:\tlearn: 0.6385945\ttotal: 3.41s\tremaining: 18.3s\n",
      "63:\tlearn: 0.6364921\ttotal: 3.47s\tremaining: 18.2s\n",
      "64:\tlearn: 0.6336265\ttotal: 3.53s\tremaining: 18.2s\n",
      "65:\tlearn: 0.6310715\ttotal: 3.57s\tremaining: 18.1s\n",
      "66:\tlearn: 0.6287156\ttotal: 3.62s\tremaining: 18s\n",
      "67:\tlearn: 0.6264715\ttotal: 3.67s\tremaining: 17.9s\n",
      "68:\tlearn: 0.6247216\ttotal: 3.72s\tremaining: 17.9s\n",
      "69:\tlearn: 0.6228681\ttotal: 3.77s\tremaining: 17.8s\n",
      "70:\tlearn: 0.6208633\ttotal: 3.82s\tremaining: 17.7s\n",
      "71:\tlearn: 0.6186796\ttotal: 3.88s\tremaining: 17.7s\n",
      "72:\tlearn: 0.6168165\ttotal: 3.94s\tremaining: 17.6s\n",
      "73:\tlearn: 0.6147824\ttotal: 3.99s\tremaining: 17.6s\n",
      "74:\tlearn: 0.6127434\ttotal: 4.05s\tremaining: 17.5s\n",
      "75:\tlearn: 0.6111515\ttotal: 4.11s\tremaining: 17.5s\n",
      "76:\tlearn: 0.6100908\ttotal: 4.16s\tremaining: 17.4s\n",
      "77:\tlearn: 0.6084039\ttotal: 4.21s\tremaining: 17.4s\n",
      "78:\tlearn: 0.6060700\ttotal: 4.27s\tremaining: 17.3s\n",
      "79:\tlearn: 0.6038885\ttotal: 4.32s\tremaining: 17.3s\n",
      "80:\tlearn: 0.6017040\ttotal: 4.38s\tremaining: 17.2s\n",
      "81:\tlearn: 0.5993562\ttotal: 4.43s\tremaining: 17.2s\n",
      "82:\tlearn: 0.5980079\ttotal: 4.49s\tremaining: 17.2s\n",
      "83:\tlearn: 0.5958721\ttotal: 4.55s\tremaining: 17.1s\n",
      "84:\tlearn: 0.5944257\ttotal: 4.6s\tremaining: 17.1s\n",
      "85:\tlearn: 0.5932372\ttotal: 4.66s\tremaining: 17s\n",
      "86:\tlearn: 0.5916723\ttotal: 4.71s\tremaining: 17s\n",
      "87:\tlearn: 0.5904128\ttotal: 4.77s\tremaining: 16.9s\n",
      "88:\tlearn: 0.5885537\ttotal: 4.82s\tremaining: 16.9s\n",
      "89:\tlearn: 0.5870539\ttotal: 4.88s\tremaining: 16.8s\n",
      "90:\tlearn: 0.5852605\ttotal: 4.94s\tremaining: 16.8s\n",
      "91:\tlearn: 0.5841739\ttotal: 4.99s\tremaining: 16.7s\n",
      "92:\tlearn: 0.5830007\ttotal: 5.04s\tremaining: 16.6s\n",
      "93:\tlearn: 0.5819964\ttotal: 5.09s\tremaining: 16.6s\n",
      "94:\tlearn: 0.5797741\ttotal: 5.15s\tremaining: 16.5s\n",
      "95:\tlearn: 0.5786647\ttotal: 5.2s\tremaining: 16.5s\n",
      "96:\tlearn: 0.5771494\ttotal: 5.26s\tremaining: 16.4s\n",
      "97:\tlearn: 0.5756873\ttotal: 5.31s\tremaining: 16.4s\n",
      "98:\tlearn: 0.5748555\ttotal: 5.37s\tremaining: 16.3s\n",
      "99:\tlearn: 0.5736790\ttotal: 5.43s\tremaining: 16.3s\n",
      "100:\tlearn: 0.5723927\ttotal: 5.49s\tremaining: 16.2s\n",
      "101:\tlearn: 0.5698143\ttotal: 5.55s\tremaining: 16.2s\n",
      "102:\tlearn: 0.5683169\ttotal: 5.61s\tremaining: 16.2s\n",
      "103:\tlearn: 0.5667438\ttotal: 5.67s\tremaining: 16.1s\n",
      "104:\tlearn: 0.5653845\ttotal: 5.72s\tremaining: 16.1s\n",
      "105:\tlearn: 0.5632557\ttotal: 5.78s\tremaining: 16s\n",
      "106:\tlearn: 0.5617493\ttotal: 5.83s\tremaining: 16s\n",
      "107:\tlearn: 0.5606846\ttotal: 5.89s\tremaining: 15.9s\n",
      "108:\tlearn: 0.5597939\ttotal: 5.95s\tremaining: 15.9s\n",
      "109:\tlearn: 0.5581382\ttotal: 6.01s\tremaining: 15.8s\n",
      "110:\tlearn: 0.5572177\ttotal: 6.07s\tremaining: 15.8s\n",
      "111:\tlearn: 0.5562534\ttotal: 6.12s\tremaining: 15.7s\n",
      "112:\tlearn: 0.5541285\ttotal: 6.18s\tremaining: 15.7s\n",
      "113:\tlearn: 0.5524108\ttotal: 6.24s\tremaining: 15.6s\n",
      "114:\tlearn: 0.5510638\ttotal: 6.29s\tremaining: 15.6s\n",
      "115:\tlearn: 0.5491823\ttotal: 6.35s\tremaining: 15.5s\n",
      "116:\tlearn: 0.5480899\ttotal: 6.41s\tremaining: 15.5s\n",
      "117:\tlearn: 0.5469744\ttotal: 6.46s\tremaining: 15.5s\n",
      "118:\tlearn: 0.5458277\ttotal: 6.52s\tremaining: 15.4s\n",
      "119:\tlearn: 0.5449160\ttotal: 6.58s\tremaining: 15.4s\n",
      "120:\tlearn: 0.5432198\ttotal: 6.64s\tremaining: 15.3s\n",
      "121:\tlearn: 0.5422637\ttotal: 6.7s\tremaining: 15.3s\n",
      "122:\tlearn: 0.5413003\ttotal: 6.76s\tremaining: 15.2s\n",
      "123:\tlearn: 0.5404437\ttotal: 6.81s\tremaining: 15.2s\n",
      "124:\tlearn: 0.5398668\ttotal: 6.86s\tremaining: 15.1s\n",
      "125:\tlearn: 0.5385898\ttotal: 6.92s\tremaining: 15s\n",
      "126:\tlearn: 0.5374408\ttotal: 6.97s\tremaining: 15s\n",
      "127:\tlearn: 0.5365721\ttotal: 7.02s\tremaining: 14.9s\n",
      "128:\tlearn: 0.5352637\ttotal: 7.08s\tremaining: 14.9s\n",
      "129:\tlearn: 0.5338737\ttotal: 7.13s\tremaining: 14.8s\n",
      "130:\tlearn: 0.5331123\ttotal: 7.18s\tremaining: 14.7s\n",
      "131:\tlearn: 0.5323192\ttotal: 7.23s\tremaining: 14.7s\n",
      "132:\tlearn: 0.5312141\ttotal: 7.29s\tremaining: 14.6s\n",
      "133:\tlearn: 0.5300222\ttotal: 7.34s\tremaining: 14.6s\n",
      "134:\tlearn: 0.5288253\ttotal: 7.39s\tremaining: 14.5s\n",
      "135:\tlearn: 0.5283713\ttotal: 7.45s\tremaining: 14.5s\n",
      "136:\tlearn: 0.5276483\ttotal: 7.49s\tremaining: 14.4s\n",
      "137:\tlearn: 0.5263007\ttotal: 7.55s\tremaining: 14.3s\n",
      "138:\tlearn: 0.5254253\ttotal: 7.6s\tremaining: 14.3s\n",
      "139:\tlearn: 0.5247394\ttotal: 7.65s\tremaining: 14.2s\n",
      "140:\tlearn: 0.5240781\ttotal: 7.7s\tremaining: 14.1s\n",
      "141:\tlearn: 0.5231874\ttotal: 7.76s\tremaining: 14.1s\n",
      "142:\tlearn: 0.5223464\ttotal: 7.82s\tremaining: 14s\n",
      "143:\tlearn: 0.5217360\ttotal: 7.87s\tremaining: 14s\n",
      "144:\tlearn: 0.5211696\ttotal: 7.91s\tremaining: 13.9s\n",
      "145:\tlearn: 0.5191623\ttotal: 7.96s\tremaining: 13.9s\n",
      "146:\tlearn: 0.5181092\ttotal: 8.02s\tremaining: 13.8s\n",
      "147:\tlearn: 0.5171374\ttotal: 8.06s\tremaining: 13.7s\n",
      "148:\tlearn: 0.5163327\ttotal: 8.11s\tremaining: 13.7s\n",
      "149:\tlearn: 0.5152494\ttotal: 8.16s\tremaining: 13.6s\n",
      "150:\tlearn: 0.5141439\ttotal: 8.22s\tremaining: 13.6s\n",
      "151:\tlearn: 0.5134419\ttotal: 8.28s\tremaining: 13.5s\n",
      "152:\tlearn: 0.5120410\ttotal: 8.32s\tremaining: 13.4s\n",
      "153:\tlearn: 0.5112070\ttotal: 8.37s\tremaining: 13.4s\n",
      "154:\tlearn: 0.5104544\ttotal: 8.42s\tremaining: 13.3s\n",
      "155:\tlearn: 0.5098068\ttotal: 8.47s\tremaining: 13.3s\n",
      "156:\tlearn: 0.5087081\ttotal: 8.53s\tremaining: 13.2s\n",
      "157:\tlearn: 0.5081140\ttotal: 8.58s\tremaining: 13.1s\n",
      "158:\tlearn: 0.5075825\ttotal: 8.63s\tremaining: 13.1s\n",
      "159:\tlearn: 0.5064501\ttotal: 8.69s\tremaining: 13s\n",
      "160:\tlearn: 0.5055097\ttotal: 8.74s\tremaining: 13s\n",
      "161:\tlearn: 0.5046602\ttotal: 8.79s\tremaining: 12.9s\n",
      "162:\tlearn: 0.5036703\ttotal: 8.84s\tremaining: 12.9s\n",
      "163:\tlearn: 0.5026709\ttotal: 8.9s\tremaining: 12.8s\n",
      "164:\tlearn: 0.5018862\ttotal: 8.95s\tremaining: 12.8s\n",
      "165:\tlearn: 0.5007884\ttotal: 9s\tremaining: 12.7s\n",
      "166:\tlearn: 0.4997001\ttotal: 9.06s\tremaining: 12.6s\n",
      "167:\tlearn: 0.4990739\ttotal: 9.1s\tremaining: 12.6s\n",
      "168:\tlearn: 0.4973509\ttotal: 9.15s\tremaining: 12.5s\n",
      "169:\tlearn: 0.4963588\ttotal: 9.21s\tremaining: 12.5s\n",
      "170:\tlearn: 0.4956625\ttotal: 9.26s\tremaining: 12.4s\n",
      "171:\tlearn: 0.4948940\ttotal: 9.32s\tremaining: 12.3s\n",
      "172:\tlearn: 0.4939914\ttotal: 9.37s\tremaining: 12.3s\n",
      "173:\tlearn: 0.4931698\ttotal: 9.42s\tremaining: 12.2s\n",
      "174:\tlearn: 0.4925662\ttotal: 9.47s\tremaining: 12.2s\n",
      "175:\tlearn: 0.4916327\ttotal: 9.52s\tremaining: 12.1s\n",
      "176:\tlearn: 0.4907326\ttotal: 9.57s\tremaining: 12.1s\n",
      "177:\tlearn: 0.4898006\ttotal: 9.63s\tremaining: 12s\n",
      "178:\tlearn: 0.4890591\ttotal: 9.68s\tremaining: 12s\n",
      "179:\tlearn: 0.4883591\ttotal: 9.73s\tremaining: 11.9s\n",
      "180:\tlearn: 0.4873839\ttotal: 9.78s\tremaining: 11.8s\n",
      "181:\tlearn: 0.4863846\ttotal: 9.83s\tremaining: 11.8s\n",
      "182:\tlearn: 0.4860107\ttotal: 9.89s\tremaining: 11.7s\n",
      "183:\tlearn: 0.4851044\ttotal: 9.94s\tremaining: 11.7s\n",
      "184:\tlearn: 0.4847495\ttotal: 9.99s\tremaining: 11.6s\n",
      "185:\tlearn: 0.4839475\ttotal: 10s\tremaining: 11.6s\n",
      "186:\tlearn: 0.4834513\ttotal: 10.1s\tremaining: 11.5s\n",
      "187:\tlearn: 0.4830322\ttotal: 10.2s\tremaining: 11.5s\n",
      "188:\tlearn: 0.4825742\ttotal: 10.2s\tremaining: 11.4s\n",
      "189:\tlearn: 0.4815406\ttotal: 10.3s\tremaining: 11.3s\n",
      "190:\tlearn: 0.4807665\ttotal: 10.3s\tremaining: 11.3s\n",
      "191:\tlearn: 0.4795943\ttotal: 10.4s\tremaining: 11.2s\n",
      "192:\tlearn: 0.4787603\ttotal: 10.4s\tremaining: 11.2s\n",
      "193:\tlearn: 0.4778573\ttotal: 10.5s\tremaining: 11.1s\n",
      "194:\tlearn: 0.4770900\ttotal: 10.5s\tremaining: 11.1s\n",
      "195:\tlearn: 0.4761500\ttotal: 10.6s\tremaining: 11s\n",
      "196:\tlearn: 0.4756450\ttotal: 10.6s\tremaining: 10.9s\n",
      "197:\tlearn: 0.4748339\ttotal: 10.7s\tremaining: 10.9s\n",
      "198:\tlearn: 0.4743435\ttotal: 10.7s\tremaining: 10.8s\n",
      "199:\tlearn: 0.4738008\ttotal: 10.8s\tremaining: 10.8s\n",
      "200:\tlearn: 0.4734806\ttotal: 10.8s\tremaining: 10.7s\n",
      "201:\tlearn: 0.4731007\ttotal: 10.9s\tremaining: 10.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202:\tlearn: 0.4724227\ttotal: 10.9s\tremaining: 10.6s\n",
      "203:\tlearn: 0.4716399\ttotal: 11s\tremaining: 10.6s\n",
      "204:\tlearn: 0.4703846\ttotal: 11.1s\tremaining: 10.5s\n",
      "205:\tlearn: 0.4697873\ttotal: 11.1s\tremaining: 10.5s\n",
      "206:\tlearn: 0.4693274\ttotal: 11.2s\tremaining: 10.4s\n",
      "207:\tlearn: 0.4689889\ttotal: 11.2s\tremaining: 10.3s\n",
      "208:\tlearn: 0.4686339\ttotal: 11.3s\tremaining: 10.3s\n",
      "209:\tlearn: 0.4680081\ttotal: 11.3s\tremaining: 10.2s\n",
      "210:\tlearn: 0.4674283\ttotal: 11.4s\tremaining: 10.2s\n",
      "211:\tlearn: 0.4667262\ttotal: 11.4s\tremaining: 10.1s\n",
      "212:\tlearn: 0.4659543\ttotal: 11.5s\tremaining: 10.1s\n",
      "213:\tlearn: 0.4656052\ttotal: 11.5s\tremaining: 10s\n",
      "214:\tlearn: 0.4650380\ttotal: 11.6s\tremaining: 9.98s\n",
      "215:\tlearn: 0.4644012\ttotal: 11.7s\tremaining: 9.94s\n",
      "216:\tlearn: 0.4636941\ttotal: 11.7s\tremaining: 9.88s\n",
      "217:\tlearn: 0.4628440\ttotal: 11.8s\tremaining: 9.83s\n",
      "218:\tlearn: 0.4618202\ttotal: 11.8s\tremaining: 9.78s\n",
      "219:\tlearn: 0.4611339\ttotal: 11.9s\tremaining: 9.72s\n",
      "220:\tlearn: 0.4605796\ttotal: 11.9s\tremaining: 9.66s\n",
      "221:\tlearn: 0.4599637\ttotal: 12s\tremaining: 9.61s\n",
      "222:\tlearn: 0.4589367\ttotal: 12s\tremaining: 9.55s\n",
      "223:\tlearn: 0.4585441\ttotal: 12.1s\tremaining: 9.49s\n",
      "224:\tlearn: 0.4578638\ttotal: 12.1s\tremaining: 9.44s\n",
      "225:\tlearn: 0.4574539\ttotal: 12.2s\tremaining: 9.38s\n",
      "226:\tlearn: 0.4568055\ttotal: 12.2s\tremaining: 9.32s\n",
      "227:\tlearn: 0.4559936\ttotal: 12.3s\tremaining: 9.27s\n",
      "228:\tlearn: 0.4551933\ttotal: 12.3s\tremaining: 9.21s\n",
      "229:\tlearn: 0.4549320\ttotal: 12.4s\tremaining: 9.16s\n",
      "230:\tlearn: 0.4542113\ttotal: 12.4s\tremaining: 9.1s\n",
      "231:\tlearn: 0.4536770\ttotal: 12.5s\tremaining: 9.05s\n",
      "232:\tlearn: 0.4525818\ttotal: 12.5s\tremaining: 8.99s\n",
      "233:\tlearn: 0.4520944\ttotal: 12.6s\tremaining: 8.93s\n",
      "234:\tlearn: 0.4516074\ttotal: 12.7s\tremaining: 8.88s\n",
      "235:\tlearn: 0.4513168\ttotal: 12.7s\tremaining: 8.83s\n",
      "236:\tlearn: 0.4505891\ttotal: 12.8s\tremaining: 8.78s\n",
      "237:\tlearn: 0.4497185\ttotal: 12.8s\tremaining: 8.73s\n",
      "238:\tlearn: 0.4493565\ttotal: 12.9s\tremaining: 8.68s\n",
      "239:\tlearn: 0.4487635\ttotal: 12.9s\tremaining: 8.62s\n",
      "240:\tlearn: 0.4478649\ttotal: 13s\tremaining: 8.57s\n",
      "241:\tlearn: 0.4473182\ttotal: 13s\tremaining: 8.51s\n",
      "242:\tlearn: 0.4466895\ttotal: 13.1s\tremaining: 8.45s\n",
      "243:\tlearn: 0.4459988\ttotal: 13.1s\tremaining: 8.39s\n",
      "244:\tlearn: 0.4454623\ttotal: 13.2s\tremaining: 8.33s\n",
      "245:\tlearn: 0.4450590\ttotal: 13.2s\tremaining: 8.28s\n",
      "246:\tlearn: 0.4446286\ttotal: 13.3s\tremaining: 8.22s\n",
      "247:\tlearn: 0.4440943\ttotal: 13.3s\tremaining: 8.17s\n",
      "248:\tlearn: 0.4434619\ttotal: 13.4s\tremaining: 8.11s\n",
      "249:\tlearn: 0.4430288\ttotal: 13.4s\tremaining: 8.06s\n",
      "250:\tlearn: 0.4426319\ttotal: 13.5s\tremaining: 8s\n",
      "251:\tlearn: 0.4419846\ttotal: 13.5s\tremaining: 7.95s\n",
      "252:\tlearn: 0.4415516\ttotal: 13.6s\tremaining: 7.89s\n",
      "253:\tlearn: 0.4412504\ttotal: 13.6s\tremaining: 7.83s\n",
      "254:\tlearn: 0.4407864\ttotal: 13.7s\tremaining: 7.78s\n",
      "255:\tlearn: 0.4404231\ttotal: 13.7s\tremaining: 7.73s\n",
      "256:\tlearn: 0.4397636\ttotal: 13.8s\tremaining: 7.67s\n",
      "257:\tlearn: 0.4394373\ttotal: 13.8s\tremaining: 7.61s\n",
      "258:\tlearn: 0.4389090\ttotal: 13.9s\tremaining: 7.56s\n",
      "259:\tlearn: 0.4386745\ttotal: 13.9s\tremaining: 7.51s\n",
      "260:\tlearn: 0.4383438\ttotal: 14.1s\tremaining: 7.49s\n",
      "261:\tlearn: 0.4375362\ttotal: 14.1s\tremaining: 7.44s\n",
      "262:\tlearn: 0.4369113\ttotal: 14.2s\tremaining: 7.39s\n",
      "263:\tlearn: 0.4363761\ttotal: 14.2s\tremaining: 7.34s\n",
      "264:\tlearn: 0.4358467\ttotal: 14.3s\tremaining: 7.28s\n",
      "265:\tlearn: 0.4351694\ttotal: 14.4s\tremaining: 7.23s\n",
      "266:\tlearn: 0.4347677\ttotal: 14.4s\tremaining: 7.18s\n",
      "267:\tlearn: 0.4344226\ttotal: 14.5s\tremaining: 7.13s\n",
      "268:\tlearn: 0.4339118\ttotal: 14.5s\tremaining: 7.07s\n",
      "269:\tlearn: 0.4334071\ttotal: 14.6s\tremaining: 7.02s\n",
      "270:\tlearn: 0.4330094\ttotal: 14.6s\tremaining: 6.96s\n",
      "271:\tlearn: 0.4324432\ttotal: 14.7s\tremaining: 6.91s\n",
      "272:\tlearn: 0.4319390\ttotal: 14.7s\tremaining: 6.85s\n",
      "273:\tlearn: 0.4315090\ttotal: 14.8s\tremaining: 6.8s\n",
      "274:\tlearn: 0.4310714\ttotal: 14.8s\tremaining: 6.75s\n",
      "275:\tlearn: 0.4307313\ttotal: 14.9s\tremaining: 6.69s\n",
      "276:\tlearn: 0.4300909\ttotal: 14.9s\tremaining: 6.63s\n",
      "277:\tlearn: 0.4296016\ttotal: 15s\tremaining: 6.58s\n",
      "278:\tlearn: 0.4291266\ttotal: 15s\tremaining: 6.52s\n",
      "279:\tlearn: 0.4287282\ttotal: 15.1s\tremaining: 6.47s\n",
      "280:\tlearn: 0.4280803\ttotal: 15.1s\tremaining: 6.41s\n",
      "281:\tlearn: 0.4276025\ttotal: 15.2s\tremaining: 6.36s\n",
      "282:\tlearn: 0.4271845\ttotal: 15.3s\tremaining: 6.31s\n",
      "283:\tlearn: 0.4267208\ttotal: 15.3s\tremaining: 6.25s\n",
      "284:\tlearn: 0.4264743\ttotal: 15.4s\tremaining: 6.2s\n",
      "285:\tlearn: 0.4259843\ttotal: 15.4s\tremaining: 6.14s\n",
      "286:\tlearn: 0.4255552\ttotal: 15.5s\tremaining: 6.09s\n",
      "287:\tlearn: 0.4248908\ttotal: 15.5s\tremaining: 6.04s\n",
      "288:\tlearn: 0.4245737\ttotal: 15.6s\tremaining: 5.98s\n",
      "289:\tlearn: 0.4240300\ttotal: 15.6s\tremaining: 5.92s\n",
      "290:\tlearn: 0.4235496\ttotal: 15.7s\tremaining: 5.87s\n",
      "291:\tlearn: 0.4232310\ttotal: 15.7s\tremaining: 5.82s\n",
      "292:\tlearn: 0.4226385\ttotal: 15.8s\tremaining: 5.76s\n",
      "293:\tlearn: 0.4222566\ttotal: 15.8s\tremaining: 5.71s\n",
      "294:\tlearn: 0.4216195\ttotal: 15.9s\tremaining: 5.65s\n",
      "295:\tlearn: 0.4213804\ttotal: 15.9s\tremaining: 5.6s\n",
      "296:\tlearn: 0.4210942\ttotal: 16s\tremaining: 5.54s\n",
      "297:\tlearn: 0.4207670\ttotal: 16s\tremaining: 5.49s\n",
      "298:\tlearn: 0.4203161\ttotal: 16.1s\tremaining: 5.43s\n",
      "299:\tlearn: 0.4201605\ttotal: 16.1s\tremaining: 5.38s\n",
      "300:\tlearn: 0.4196009\ttotal: 16.2s\tremaining: 5.33s\n",
      "301:\tlearn: 0.4189433\ttotal: 16.2s\tremaining: 5.27s\n",
      "302:\tlearn: 0.4183852\ttotal: 16.3s\tremaining: 5.22s\n",
      "303:\tlearn: 0.4180194\ttotal: 16.4s\tremaining: 5.16s\n",
      "304:\tlearn: 0.4175472\ttotal: 16.4s\tremaining: 5.11s\n",
      "305:\tlearn: 0.4172428\ttotal: 16.5s\tremaining: 5.05s\n",
      "306:\tlearn: 0.4169825\ttotal: 16.5s\tremaining: 5s\n",
      "307:\tlearn: 0.4166248\ttotal: 16.6s\tremaining: 4.95s\n",
      "308:\tlearn: 0.4158584\ttotal: 16.6s\tremaining: 4.89s\n",
      "309:\tlearn: 0.4153703\ttotal: 16.7s\tremaining: 4.84s\n",
      "310:\tlearn: 0.4150613\ttotal: 16.7s\tremaining: 4.79s\n",
      "311:\tlearn: 0.4148446\ttotal: 16.8s\tremaining: 4.73s\n",
      "312:\tlearn: 0.4143442\ttotal: 16.8s\tremaining: 4.68s\n",
      "313:\tlearn: 0.4139272\ttotal: 16.9s\tremaining: 4.63s\n",
      "314:\tlearn: 0.4135531\ttotal: 16.9s\tremaining: 4.57s\n",
      "315:\tlearn: 0.4132359\ttotal: 17s\tremaining: 4.51s\n",
      "316:\tlearn: 0.4129405\ttotal: 17s\tremaining: 4.46s\n",
      "317:\tlearn: 0.4126209\ttotal: 17.1s\tremaining: 4.41s\n",
      "318:\tlearn: 0.4123267\ttotal: 17.1s\tremaining: 4.35s\n",
      "319:\tlearn: 0.4119051\ttotal: 17.2s\tremaining: 4.3s\n",
      "320:\tlearn: 0.4113391\ttotal: 17.3s\tremaining: 4.25s\n",
      "321:\tlearn: 0.4109971\ttotal: 17.3s\tremaining: 4.19s\n",
      "322:\tlearn: 0.4102379\ttotal: 17.4s\tremaining: 4.14s\n",
      "323:\tlearn: 0.4097213\ttotal: 17.4s\tremaining: 4.08s\n",
      "324:\tlearn: 0.4091161\ttotal: 17.5s\tremaining: 4.03s\n",
      "325:\tlearn: 0.4086624\ttotal: 17.5s\tremaining: 3.98s\n",
      "326:\tlearn: 0.4081971\ttotal: 17.6s\tremaining: 3.92s\n",
      "327:\tlearn: 0.4076739\ttotal: 17.6s\tremaining: 3.87s\n",
      "328:\tlearn: 0.4072410\ttotal: 17.7s\tremaining: 3.81s\n",
      "329:\tlearn: 0.4069908\ttotal: 17.7s\tremaining: 3.76s\n",
      "330:\tlearn: 0.4064578\ttotal: 17.8s\tremaining: 3.71s\n",
      "331:\tlearn: 0.4062672\ttotal: 17.8s\tremaining: 3.65s\n",
      "332:\tlearn: 0.4058798\ttotal: 17.9s\tremaining: 3.6s\n",
      "333:\tlearn: 0.4055643\ttotal: 17.9s\tremaining: 3.54s\n",
      "334:\tlearn: 0.4049764\ttotal: 18s\tremaining: 3.49s\n",
      "335:\tlearn: 0.4047265\ttotal: 18.1s\tremaining: 3.44s\n",
      "336:\tlearn: 0.4044371\ttotal: 18.1s\tremaining: 3.38s\n",
      "337:\tlearn: 0.4041056\ttotal: 18.2s\tremaining: 3.33s\n",
      "338:\tlearn: 0.4035600\ttotal: 18.2s\tremaining: 3.27s\n",
      "339:\tlearn: 0.4030451\ttotal: 18.3s\tremaining: 3.22s\n",
      "340:\tlearn: 0.4024657\ttotal: 18.3s\tremaining: 3.17s\n",
      "341:\tlearn: 0.4020382\ttotal: 18.4s\tremaining: 3.11s\n",
      "342:\tlearn: 0.4014636\ttotal: 18.4s\tremaining: 3.06s\n",
      "343:\tlearn: 0.4010739\ttotal: 18.5s\tremaining: 3s\n",
      "344:\tlearn: 0.4008341\ttotal: 18.5s\tremaining: 2.95s\n",
      "345:\tlearn: 0.4004619\ttotal: 18.6s\tremaining: 2.9s\n",
      "346:\tlearn: 0.4002910\ttotal: 18.6s\tremaining: 2.84s\n",
      "347:\tlearn: 0.3998898\ttotal: 18.7s\tremaining: 2.79s\n",
      "348:\tlearn: 0.3995658\ttotal: 18.7s\tremaining: 2.74s\n",
      "349:\tlearn: 0.3990756\ttotal: 18.8s\tremaining: 2.68s\n",
      "350:\tlearn: 0.3985180\ttotal: 18.8s\tremaining: 2.63s\n",
      "351:\tlearn: 0.3981483\ttotal: 18.9s\tremaining: 2.58s\n",
      "352:\tlearn: 0.3977495\ttotal: 18.9s\tremaining: 2.52s\n",
      "353:\tlearn: 0.3973062\ttotal: 19s\tremaining: 2.47s\n",
      "354:\tlearn: 0.3969306\ttotal: 19s\tremaining: 2.41s\n",
      "355:\tlearn: 0.3965909\ttotal: 19.1s\tremaining: 2.36s\n",
      "356:\tlearn: 0.3961942\ttotal: 19.1s\tremaining: 2.31s\n",
      "357:\tlearn: 0.3958367\ttotal: 19.2s\tremaining: 2.25s\n",
      "358:\tlearn: 0.3952590\ttotal: 19.3s\tremaining: 2.2s\n",
      "359:\tlearn: 0.3945111\ttotal: 19.3s\tremaining: 2.15s\n",
      "360:\tlearn: 0.3942265\ttotal: 19.4s\tremaining: 2.09s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361:\tlearn: 0.3939894\ttotal: 19.4s\tremaining: 2.04s\n",
      "362:\tlearn: 0.3935715\ttotal: 19.5s\tremaining: 1.98s\n",
      "363:\tlearn: 0.3930744\ttotal: 19.5s\tremaining: 1.93s\n",
      "364:\tlearn: 0.3927336\ttotal: 19.6s\tremaining: 1.88s\n",
      "365:\tlearn: 0.3924006\ttotal: 19.6s\tremaining: 1.82s\n",
      "366:\tlearn: 0.3920940\ttotal: 19.7s\tremaining: 1.77s\n",
      "367:\tlearn: 0.3916102\ttotal: 19.7s\tremaining: 1.71s\n",
      "368:\tlearn: 0.3911981\ttotal: 19.8s\tremaining: 1.66s\n",
      "369:\tlearn: 0.3907652\ttotal: 19.8s\tremaining: 1.61s\n",
      "370:\tlearn: 0.3903434\ttotal: 19.9s\tremaining: 1.55s\n",
      "371:\tlearn: 0.3900391\ttotal: 19.9s\tremaining: 1.5s\n",
      "372:\tlearn: 0.3896032\ttotal: 20s\tremaining: 1.45s\n",
      "373:\tlearn: 0.3893299\ttotal: 20s\tremaining: 1.39s\n",
      "374:\tlearn: 0.3888758\ttotal: 20.1s\tremaining: 1.34s\n",
      "375:\tlearn: 0.3887067\ttotal: 20.1s\tremaining: 1.28s\n",
      "376:\tlearn: 0.3885596\ttotal: 20.2s\tremaining: 1.23s\n",
      "377:\tlearn: 0.3882201\ttotal: 20.2s\tremaining: 1.18s\n",
      "378:\tlearn: 0.3877925\ttotal: 20.3s\tremaining: 1.12s\n",
      "379:\tlearn: 0.3873624\ttotal: 20.3s\tremaining: 1.07s\n",
      "380:\tlearn: 0.3869238\ttotal: 20.4s\tremaining: 1.02s\n",
      "381:\tlearn: 0.3864723\ttotal: 20.4s\tremaining: 963ms\n",
      "382:\tlearn: 0.3858475\ttotal: 20.5s\tremaining: 909ms\n",
      "383:\tlearn: 0.3854567\ttotal: 20.5s\tremaining: 856ms\n",
      "384:\tlearn: 0.3851813\ttotal: 20.6s\tremaining: 802ms\n",
      "385:\tlearn: 0.3849620\ttotal: 20.6s\tremaining: 748ms\n",
      "386:\tlearn: 0.3845939\ttotal: 20.7s\tremaining: 695ms\n",
      "387:\tlearn: 0.3839869\ttotal: 20.7s\tremaining: 641ms\n",
      "388:\tlearn: 0.3834559\ttotal: 20.8s\tremaining: 588ms\n",
      "389:\tlearn: 0.3830330\ttotal: 20.8s\tremaining: 534ms\n",
      "390:\tlearn: 0.3827580\ttotal: 20.9s\tremaining: 481ms\n",
      "391:\tlearn: 0.3824301\ttotal: 20.9s\tremaining: 428ms\n",
      "392:\tlearn: 0.3822362\ttotal: 21s\tremaining: 374ms\n",
      "393:\tlearn: 0.3818810\ttotal: 21.1s\tremaining: 321ms\n",
      "394:\tlearn: 0.3814722\ttotal: 21.1s\tremaining: 267ms\n",
      "395:\tlearn: 0.3808457\ttotal: 21.2s\tremaining: 214ms\n",
      "396:\tlearn: 0.3804607\ttotal: 21.2s\tremaining: 160ms\n",
      "397:\tlearn: 0.3801179\ttotal: 21.3s\tremaining: 107ms\n",
      "398:\tlearn: 0.3798047\ttotal: 21.3s\tremaining: 53.4ms\n",
      "399:\tlearn: 0.3795623\ttotal: 21.4s\tremaining: 0us\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['일시'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15152\\4061279142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# ARIMA 모델 예측 수행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0marima_forecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marima_forecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'일시'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'풍속 (m/s)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'일시'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# 앙상블 결과와 스태킹 결과를 평균하여 최종 예측값 도출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['일시'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 학습\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "cat_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "lr_model.fit(X_train, y_train)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# 각 모델의 예측 결과를 가져옵니다.\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "cat_pred = cat_model.predict(X_test)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "svr_pred = svr_model.predict(X_test)\n",
    "\n",
    "# 앙상블 모델 예측\n",
    "ensemble_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# 스태킹 모델 예측\n",
    "stacking_pred = stacking_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec5be061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "풍속 예측이 완료되었습니다. 결과가 submission.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 결과와 스태킹 결과를 평균하여 최종 예측값 도출\n",
    "final_pred = (ensemble_pred + stacking_pred + rf_pred + xgb_pred + lgb_pred + cat_pred + gb_pred + lr_pred + svr_pred) / 9\n",
    "\n",
    "# Submit / 제출\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['풍속 (m/s)'] = final_pred\n",
    "\n",
    "# 예측 결과를 submission.csv 양식에 맞게 저장합니다.\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"풍속 예측이 완료되었습니다. 결과가 submission.csv에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399f1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
